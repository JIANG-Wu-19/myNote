# Computer Architecture

**key**

* IO原理
* 存储层次
* 流水线并行计算的原理

---

[TOC]

---

## 计算机系统结构概念

### 计算机系统结构

$系统效率=min(器件速度)*min(系统结构效率)$

计算机体系结构是软件设计者与硬件设备设计者（VLSI）之间的中间层，是软件与硬件的接口（Interface）

程序员可见的计算系统的属性。包括：概念性的结构和功能行为（外特性）。不包括：数据流和控制流的组织、逻辑设计以及物理实现

#### 结构特性

##### 层次结构

![image-20230919141845531](imgs/1.png)

分层带来的透明性

#### 系统结构内容

指令系统、数据表示、寻址方式、寄存器组织、存储系统、终端机构、IO结构、及其工作状态定义切换、信息保护

#### 计算机体系结构的分类

1. 按处理机性能分类

   * 按大小划分

     巨型、大型、中型、小型、微型机
   * 按用途划分

     **科学计算、事务处理、实时控制、工作站、服务器、家用计算机**
   * 按数据类型划分

     定点计算机、浮点计算机、向量计算机、堆栈计算机
   * 按处理机个数和种类划分

     单处理机

     并行处理机、多处理机、分布处理机

     关联处理机

     超标量处理机, 超流水线处理机, VLIW处理机

     SMP(对称多处理机)、MPP(大规模并行处理机)、机群(Cluster)系统
   * 使用器件划分

     第一代：电子管(Valve)计算机

     第二代：晶体管(Transistor)计算机

     第三代：集成电路(LSI)计算机

     第四代：大规模集成电路(VLSI)计算机

     第五代：智能计算机

2. 按“流”分类：Flynn分类法

   * 概念

     指令流（Instruction Stream）：机器执行的**指令序列**；

     数据流（Data stream）：由指令处理的**数据序列**；

     多倍性（Multiplicity）：在系统最窄的部件上，处于**同一执行阶段**的指令和数据的最大可能个数。
   * 基本模块

     MM（Memory Module）：内存模块

     PU（Process Unit）：处理单元

     CU（Control Unit）：控制单元
   * 指令流和数据流的个数

     * 单指令流单数据流SISD

       ![image-20230919151309716](imgs/2.png)
     * 单指令流多数据流SIMD

       ![1695107777668](imgs/3.png)
     * 多指令流单数据流MISD

       ![1695107968627](imgs/4.png)

       * 没有MISD计算机的原因之一：通常PU用于处理简单数据，一般没有多个简单数据需要一组相同处理的需求，**没有存在的需求基础**
       * 没有MISD计算机的原因之二：如果把PU用于处理复杂数据（向量、矩阵等），一方面**MISD已经变成了MIMD**，另一方面，相对于**SIMD性能价格比较低**
       * 没有MISD计算机的原因之三：适合MISD实现的应用都可以使用其它结构实现，没有存在的必然性，**因为任何复杂数据都可以分解为简单数据**。
     * 多指令流多数据流MIMD

       ![1695108484531](imgs/5.png)
   * 主要缺点

     * 分类太粗
     * 把两个不同等级的功能并列对待
     * 没有非冯计算机的分类

3. 库克分类法

   按控制流和执行流分类

   * 单指令流单执行流SISE
   * 单指令流多执行流SIME

     多功能部件处理机、相联处理机、向量处理机、流水线处理机、超流水线处理机、超标量处理机、SIMD并行处理机
   * 多指令流单执行流MISE
   * 多指令流多执行流MIME

   缺点：

   有些系统如分布处理机等，没有总控制器

   分类级别太低，没有处理机级和机器级

   分类太粗，如SIME中包含了多种处理机

4. 最大并行度分类：冯氏分类法

   最大并行度$P_m$是指一个系统在单位时间内能够处理的最多的二进制位数，显然这是一个完全由计算机硬件结构决定的参数

   **最大并行度的数值越大越好**

   ![image-20230926143105299](imgs/6.png)

   * 字串位串WSBS：n=1，m=1 全串行
   * 字并位串WPBS：n>1，m=1 并行单处理机
   * 字串位并WSBP：n=1，m>1 每处理机只一位，但有多个字处理机并行运用
   * 字并位并WPBP：n>1，m>1

   如果在一个时钟周期$\Delta t_i$内实际处理的二进制位数为$P_i$，那么在$T$个时钟周期内的平均并行度$P_a$ 就为：
   $$
   P_a=(\sum_{i=1}^T P_i)/T
   $$
   把平均并行度与最大并行度之比称为平均利用率，用$\mu$表示为：
   $$
   \mu=P_a/P_m= \frac{\sum_{i=1}^TP_i}{T \cdot P_m}
   $$

5. 按“并行集”和“流水线”分类：$Handler$表示法

   根据可并行和流水处理的程度，将硬件分成三个层次：

   * 程序控制部件（PCU）的个数$k$
   * 算术逻辑部件（ALU）或处理部件（PE）的个数$k$
   * 每个算逻部件包含基本逻辑线路（ECL）的套数$w$

   每一个计算机系统都可以用上述三个参数表示其结构特征，即：
   $$
   t(系统型号)=(k,d,w)
   $$
   更细致的表达：
   $$
   t(系统型号)=(k \times k',d \times d',w \times w')
   $$
   $k'$表示宏流水线中程序控制部件的个数；

   $d'$表示指令流水线中算术逻辑部件的个数；

   $w'$表示操作流水线中基本逻辑线路的套数

6. 按控制方式分类

   控制流方式：顺序执行（冯·诺伊曼型）

   数据流方式：操作数到位即可运算，无序执行

   规约方式：驱动方式与数据流相反

   匹配方式：非数值型应用，主要对象为符号

7. 按系统结构风格分类

   面向堆栈型、面向寄存器型、面向对象型

### 系统结构设计

#### 设计思路

1. 由上向下方法

   适合于专用机的设计，从应用到实现级，周期几年。

   缺点：当应用对象或范围变化时，效率急剧下降。

   原因：软、硬件脱节，不能利用最新的软件技术。

2. 由下向上方法

   前提：硬件不能改变。

   缺点：易形成软、硬脱节，软件不能获得最新硬件的支持，结果软件繁杂、效率低。

3. 从中间开始

   从软、硬件交界面开始设计。

   要求首先进行软、硬件功能分配，同时考虑硬件能为软件提供什么支持。

   优点：避免软、硬件脱节，设计周期短，有利于优化设计。

    缺点：对设计人员要求较高，要求具有有效的软件设计环境和开发工具，便于分析、评价和设计。

#### 设计步骤

1. 需求分析
2. 需求说明
3. 概念性设计
4. 具体设计
5. 反复进行优化设计及评价

#### 量化规则

* 抽象以简化设计

* 冗余redundancy以增强独立性

* 并行

  * pipelining

  * powerful instructions

    * MD-technique

      multiple data operands per operation

    * MO-technique

      multiple operations per instruction

  * Multiple instruction issue

    * single instruction-program stream
    * multiple streams

* 关注common case

  * Favor the frequent case over the infrequent case

  * Frequent case is often simpler and can be done faster than the infrequent case

  * Amdahl's Law

    $Speedup(E)=\frac{Execution\_Time\_Without\_enhancement}{Execution\_Time\_With\_enhancement}$

    $Speedup_{overall}=\frac{ExTime_{old}}{ExTime_{new}}=\frac{1}{(1-Fraction_{enhanced})+\frac{Fraction_{enhanced}}{Speedup_{enhanced}}}$

    * 减小CPI×
    * 将CPU的流水线条数增加为n条×
    * 设计专门的多媒体指令及处理硬件

  * Gustafson's law

    $Speedup=P-f_{seq}(P-1)$

* 局部性原理

  * temporal locality
  * spatial locality

* [Performance Equation](https://cseweb.ucsd.edu/classes/sp14/cse141-a/Slides/02_performance_annotated-0417.pdf)

  * $CPU\ Time=\frac{CPU\ clock\ cycles\ for\ a\ program}{Clock\ rate}$
  * $CPI=\frac{CPU\ clock\ cycles\ for\ a\ program}{IC}$
  * $Instruction\ Count:IC$
  * $CPU=\frac{IC \times CPI}{Clockrate}$

存储层级结构

![image-20231017144327723](imgs/7.png)

#### 软硬件取舍原则

1. 现有软、硬件条件下，选择能够提高系统性能/价格的方法；
2. 考虑到准备采用和可能采用的组成技术，所选方法能否尽量不限制组成和实现技术
3. 不能仅从“硬”的角度去考虑如何便于应用组成技术的成果和发挥器件技术的进展，还应考虑所选方法能否从“软”的角度为编译和操作系统的实现，以至高级语言程序的设计提供更多更好的硬件支持

### 计算机性能标准

计算机性能：正确性、可靠性和工作能力

评价性能：仅指工作能力

工作能力指标：

* 处理能力—单位时间内能处理的信息量(吞吐率)
* 响应能力—响应时间、周转时间、排队时间
* 利用率—T时间内，某部分被使用时间t与T的比值

#### CPU能力

##### 硬件连接能力

速度指标

CPU通过在引脚上设置数据、地址和控制总线实现与外部电路的连接，这种能力的强弱常用数据总线带宽，即单位时间内传输的数据量来表示。这是一个速度指标

地址总线的宽度可以衡量CPU支持的容量指标。
控制总线的数量、性质可以衡量CPU的功能、可靠性、可扩展性等指标，但表达可能比较复杂。

1. 数据带宽
   * CPU引脚中数据总线的宽度乘以总线传输速率得到数据带宽。（注意，由CPU、系统总线共同决定）
   * 例如，数据总线的传输速率为266 MHz，总线的宽度为32位（4字节），那么该数据总线的带宽就达到2.1GB/s（266MHz×4B）。显然，数据总线带宽越宽，表明该处理机对其他部件的读写速度越快。    
   * 体系结构改善：提高总线传输速率、增加总线宽度，相应的增加成本。
2. CPU与Cache连接方式
   * 随着处理机工作速率的提高，采用Cache（高速缓冲存储器）是提高CPU工作效率的必备措施，而与Cache的连接方式也成为考察处理机连接能力的又一个重要方面
   * CPU在片内连接Cache比在片外连接Cache具有更高的速度指标
   * CPU与Cache之间的数据通道越多，则速度越快。
   * 一级CACHE集成在CPU同一芯片内
   * 二级一般也在CPU同一芯片内(全速CACHE),有的在芯片外,但与CPU 在同一专用板上且有专门通道与CPU相连。
   * 有的CPU还提供专门通道连结第三级CACHE
   * 体系结构改善：为CACHE设计足够宽的通道、尽量把Cache设计在CPU芯片内，但是这会相应增加制造难度和成本

##### 管理能力

可靠性、速度、容量、可扩展性、性能价格比

* 可靠性：多道作业管理
* 速度：Cache寻址，中断管理
* 容量：虚拟存储器寻址
* 可扩展性：中断管理
* 性能价格比：操作系统中某些软件功能放在硬件中实现，提高系统整体的性能价格比。

**CPU PE**

假定通过许多程序的统计，得知第$i$类指令的使用概率为$P_i$，而执行该类指令所需的时钟周期数为$CPI_i$，而全部指令的类别数为$n$，该处理机的统计平均$CPI$就为
$$
CPI=\sum_{i=1}^n(CPI_i \times P_i)
$$
减小平均CPI,减小频繁使用指令的CPI,大概率事件优先原则的应用

系统响应能力能反映计算机系统的软、硬件性能

不能仅用计算机主频衡量系统性能

#### 系统运行速度/处理能力

##### MIPS\MFLOPS

以计算机系统整体作为一个被评估的模块，CPI显然是不合适的

用MIPS和MFLOPS反映系统（CPU）吞吐率。
$$
MIPS=\frac{IC}{Time*10^6}=\frac{Frequency}{CPI*10^6}
$$

$$
MFLOPS=\frac{FP\ Operations}{Time*10^6}
$$

$$
1MFLOPS \approx3MIPS
$$

##### 基准测试

基准测试程序通常用高级语言编写，由各系统自带的编译程序编译成适合在本机中运行的机器码，记下各程序运行所花费的时间，然后按一定的规则计算其执行时间。

1. spec
   $$
   SPEC=\sqrt[n]{\prod_{i=1}^n SPEC_i}
   $$

2. icomp

#### 利用率

虽不直接表示系统性能指标，但与前两种指标有密切关系。对系统性能或结构改进与优化起着至关重要的作用

利用阿姆达尔定律和程序局部性原理改进来提高部件利用率

#### 性能评价技术

1. 分析技术

   近似求解算法：聚合法、均值分析法、扩散法

2. 模拟技术

   设计模拟实验，依照评价目标，选择与目标有关因素，得出实验值，再进行统计、分析

3. 测量技术

#### 多机系统性能评价

除采用单机的评价方法外，还需测试系统的性能加速比和性能可伸缩性值

1. 性能加速比

   $S(p,n)=\frac{T(p,1)}{T(p,n)+h(p,n)}$

2. 性能可伸缩性

#### 计算机成本与价格

### 计算机系统结构发展

#### 冯诺依曼机系统结构演变

运算器、控制器、存储器、IO设备

![image-20231017165717270](imgs/8.png)

![image-20231017170105396](imgs/9.png)

#### 软件、应用和器件对系统结构的影响

##### 软件对系统结构发展的影响

主要体现在软件可移植性问题

1. 统一高级语言方法
2. 系列机思想

![image-20231017171417839](imgs/10.png)

软件兼容种类：向上/下、向前/后兼容

系列机要求：保证向后兼容，力争向上兼容

3. 模拟与仿真
4. 目标代码的并行编译技术

软件是促使计算机系统结构发展最重要的因素。

##### 应用对系统结构发展的影响

* 应用要求：高速度、大容量、大吞吐率
* 应用场合：大、中、小、巨、微型机

##### 器件对系统结构发展的影响

器件的性能、使用方法改变、影响系统结构及组成方法

## 指令系统

An Instruction Set provides a functional description of a processor

* a detailed list of the **instructions** that the processor is capable of processing
* a description of the types/locations/access methods for **operands**

### Data Representation

#### 数据类型

定义：具有一组值的集合，且定义了作用于该集合的操作集。

目的：防止不同类型数据间的误操作。

分类：基本类型、结构类型。

#### 基本数据类型

内容：二进制位、二进制位串、整数、十进制数、浮点数、字符、布尔数等

所有系统结构都支持基本数据类型

#### 结构数据类型

定义：由一组相互有关的数据元素复合而成的数据类型。

分类：系统数据类型、用户自定义数据类型。

内容：数组、字符串、向量、堆栈、队列、记录等

![image-20231017191946396](imgs/11.png)

#### 引入数据表示的规则

1. whether the systematic effectiveness is improved
2. whether that data representation commonality and utilization ratio is enough 

#### Self-defining data representation 

The **feasible quality analysis**:

* whether the dedicated space improves 

  通常面积B>面积A

  ![image-20231017192828475](imgs/13.png)

* whether realization time to decrease 

* commonality and the utilization ratio 



1. Data representation including tag

   ![image-20231017192717658](imgs/12.png)

   与数据相连，共存于同一存储单元中，是数据的一部分

   **advantages**

   * Simplify the instruction set
   * chieve consistency check and the data form transformation through hardware
   * Simplify programming，Semantic disparity lessening between human and the machinery
   * Simplify compiler，The semantic disparity between high-quality language together with the machine language cuts down enormously
   * Support data base system，software can be applicable to much kinds of data type with no modification
   * Convenient software debugging，every data includes a trap bit

   **defects**

   * The length of data and instruction is probably not the same 
   * The execution speed of instruction decreases 。The design time 、Compilation time and debugging time of program be shortened.
   * Increasing The hardware complexity 

2. Data descriptor representation

   与数据分开，增加一级寻址，是程序的一部分

   ![image-20231024143015233](imgs/14.png)

   ![image-20231024143500388](imgs/15.png)

### Instruction set

* The complete collection of instructions that are understood by a CPU
* Machine Code
* Binary
* Usually represented by assembly codes

#### Elements of an Instruction

* Operation code (Op code)
  * Do this
* Source Operand reference
  * To this
* Result Operand reference
  * Put the answer here
* Next Instruction Reference
  * When you have done that, do this...

#### Instruction Cycle State Diagram

![image-20231024144342294](imgs/16.png)

#### Instruction Representation

##### Instruction Types

* Data processing
* Data storage (main memory)
* Data movement (I/O)
* Program flow control 

##### Number of Addresses

* 3 addresses
  * op1,op2,result
  * c=a+b
* 2 addresses
  * op1,op2
  * a=a+b
* 1 address
  * Implicit second address
* 0 address
  * use a stack
  * push a
  * push b
  * add
  * pop c

##### Design Decisions

* Operation decisions
  * number of ops
  * op's functions
  * complexity
* Data types
* Instruction formats
  * Length of op code field
  * Number of addresses
* Registers
* Addressing modes
* RISC vs CISC

##### Simple Instruction Format

![image-20231024145657590](imgs/17.png)

##### Operands类型、表示和大小

**常用操作数类型**

* ASCII character = 1 byte (64-bit register can store 8 characters
* Unicode character or Short integer = 2 bytes = 16 bits （half word) 
* Integer = 4 bytes = 32 bits (word size on many RISC Processors)
* Single-precision float = 4 bytes = 32 bits (word size)
* Long integer = 8 bytes = 64 bits (double word)
* Double-precision float = 8 bytes = 64 bits (double word)
* Extended-precision float = 10 bytes = 80 bits (Intel architecture)
* Quad-precision float = 16 bytes = 128 bits

##### 寻址方式

![image-20231024150929836](imgs/18.png)

重要的寻址方式：

* 偏移寻址
* 立即数寻址方式
* 寄存器间址方式

偏移字段的大小应该在12-16bits，满足75%-99%需求

立即数字段的大小应该在8-16bits，满足50%-80%需求

##### Types of Operation

* Data Transfer
* Arithmetic
* Logical
* Conversion
* I/O
* System Control
* Transfer of Control

##### 指令集结构分类

###### 分类准则

1. 根据CPU中操作数的存储方法分类；（主要分类准则）
2. 根据指令中显式操作数个数分类；
3. 根据操作数能否放在存储器中分类

指令集划分成堆栈、累加器、寄存器型三类。目前，指令系统则为三种中某些类型的混合型

### Addressing mode

重点是寻址方式的选择方法

80年以来几乎所有机器的存储器都是**按字节编址**

不同体系结构对字的定义是不同的

#### 尾端问题

* little endian
* big endian

![image-20231031141034197](imgs/19.png)

#### 对齐问题

* 对s字节的对象访问地址为A，如果A mod s =0 称为边界对齐。
* 边界对齐的原因是存储器本身读写的要求，存储器本身读写通常就是边界对齐的，对于不是边界对齐的对象的访问可能要导致存储器的两次访问，然后再拼接出所需要的数。（或发生异常）

#### 编址方式

##### 编址单位

常见编址单位有：word、byte、bit、block

一般：字节编址，字访问

部分机器：位编址，字访问

辅助存储器：块编址

##### 零地址空间

* 三个零地址空间：通用寄存器、主存储器和输入输出设备均独立编址
* 两个零地址空间：主存储器与输入输出设备统一编址
* 一个零地址空间：所有存储设备统一编址，最低端是通用寄存器，最高端是输入输出设备，中间为主存储器
* 隐含编址方式，实际上没有零地址空间：堆栈、Cache

##### 对于IO设备

* 一地址一设备：必须通过指令中的操作码来识别该输入输出设备上的有关寄存器
* 两地址一设备：一个地址是数据寄存器，一个地址是状态/控制寄存器
* 多地址一设备：对编程增加困难，常用于主存和输入输出设备统一编址的计算机系统

##### 对于并行存储

* 高位交叉编址：扩大存储器容量
* 低位交叉编址：提高存储器速度

[高位交叉和低位交叉](https://zhuanlan.zhihu.com/p/48014084#:~:text=高位交叉编址 当程序按体内地址顺序存放，即一个体存满之后，再存入下一个体时，这种方式称为 顺序存储 ，高位地址表示题号，低位表示体内地址（注意0 1 2 3....的顺序是从上往下的）： 因此，CPU给出一次存储访问总是对一块连续的存储单元进行的，在多CPU系统中，不同的CPU访问不同的存储块，达到并行工作。,低位交叉编址 对应于高位交叉编址，低位交叉编址指的是将程序连续存放在相邻体中，又称 交叉存储 。 （注意，0 1 2 3的顺序是从左往右的）)

#### 寻址方式

##### 立即数寻址方式

用于数据比较短、源操作数

##### 面向寄存器的寻址方式

##### 面向主存储器的寻址方式

#### 指令格式

Many computers support more than a single format for instructions

##### 指令长度

影响因素

* 存储器规模
* 存储器架构
* 总线结构
* CPU复杂度
* CPU速度

##### 位分配

* Number of addressing modes
* Number of operands
* Register versus memory
* Number of register sets
* Address range
* Address granularity

##### 指令格式设计

[计算机组成原理——指令格式设计_指令中的地址码字段有多少位_花生酱拌面的博客-CSDN博客](https://blog.csdn.net/m0_56561130/article/details/118516188)

##### Locating modes

* Locating directly
* locating statically
* locating dynamically

### 优化指令格式

three approaches

**fixed length**，**Huffman coding**，**extending coding**

[系统结构-2-3指令操作码的优化:哈夫曼编码_哈夫曼扩展编码规则_哑巴湖小水怪的博客-CSDN博客](https://blog.csdn.net/changhuzichangchang/article/details/119187648)

#### Huffman编码法

和数据结构中所学的huffman树没有区别

例

7种指令使用频率分别为0.4、0.26、0.15、0.06、0.05、0.04、0.04，要求对每种指令进行操作码编码

![image-20231031153106188](imgs/20.png)

#### huffman的扩展方法

##### 等长扩展

##### 不等长扩展

### 编译器优化

[编译器常用的8种优化方法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/381490718)

[编译器 - 什么是优化编译器 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/521319009)

[编译器技术_ronnie88597的博客-CSDN博客](https://blog.csdn.net/weixin_46222091/category_9729419.html)

![image-20231107153317201](imgs/21.png)

#### 高层次

done at or near source code level方法内联

* If procedure is called only once, put it in-line and save CALL
* more general case: if call-count < some threshold, put them in-line

#### 局部

done within straight-line code

* common sub-expressions produce same value – either allocate a register or replace with single copy公共子表达式消除
* constant propagation – replace constant valued variable with the constant常量传播
* stack height reduction – re-arrange expression tree to minimize temporary storage needs

#### 全局

across a branch

* copy propagation – replace all instances of a variable *A* that has been assigned *X* (i.e., *A=X*) with *X*. 复写传播

* code motion – remove code from a loop that computes same value each iteration of the loop and put it before the loop代码移动

  [编译器优化--6--代码移动_编译原理 代码移动-CSDN博客](https://blog.csdn.net/weixin_46222091/article/details/104743294)

* simplify or eliminate array addressing calculations in loops

#### Machine-dependent optimizations

based on machine knowledge

* strength reduction – replace multiply by a constant with shifts and adds
  * would make sense if there was no hardware support for MUL
  * a trickier version: $17 \times$= arithmetic left shift 4 and add
* pipelining scheduling – reorder instructions to improve pipeline performance
  * dependency analysis
* branch offset optimization - reorder code to minimize branch offsets

### Compiler techniques for exposing ILP

#### The impact of compiler technology

Three separate areas for data allocation

* Stack
  * Used to allocate **local variables**
  * Grown and shrunk on calls and returns
  * Addressing is relative to the **stack pointer**

* Global data area 
  * Used to allocate **statically declared objects**, such as **global variables and constants**
  * A large percentage of these objects are aggregate data structures such as arrays

* Heap
  * Used to allocate **dynamic objects**
  * Access are usually by pointers 
  * Data is typically not scalars (single variables)

#### Register Allocation Problem

* Reasonably simple for stack-allocated objects
  * Done with the graph coloring theory: variable – vertex; dependency between variables – edge; # register will be equal to # colors
* Essentially impossible for heap-allocated objects because they are accessed with pointers
* Hard for global variables and some static variables due to *aliasing* opportunity
  * There are multiple ways to refer to the address of a variable *b*

#### solution

* Regularity
  * Addressing modes, operations, and data types should be independent of each other

* Provide primitives, not solution
  * What works in one language may be detrimental to others, so don’t optimize for one particular language

* Simplify trade-offs among alternatives
  * Anything that makes code sequence performance obvious is a definite win!

* Provide instructions that bind the quantities known at compile time as constants

### Instruction Level Parallelism

Exploit ILP across multiple basic blocks

[ILP——指令级并行 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/55663009)

Instruction independency is the key requirement for the transformations

1. Eliminating Name Dependences

   ![image-20231114145549135](imgs/22.png)

2. Eliminating Control Dependences

   ![image-20231114145754435](imgs/23.png)

3. Eliminating Data Dependences

   ![image-20231114145844461](imgs/24.png)

4. Alleviating Data Dependencies

   ![image-20231114145933695](imgs/25.png)

#### Loop-level Parallelism

#### software pipelining

#### Trace Selection

### 指令系统的功能设计

**指令系统的完整性、规整性、高效率和兼容性**

* 完整性 是指应该具备的基本指令种类，通用计算机必须有５类基本指令

* 规整性 包括对称性和均匀性
* 对称性：所有寄存器同等对待，操作码的设置等都要对称，如：A－B与B－A
* 均匀性：不同的数据类型、字长、存储设备、操作种类要设置相同的指令
* 高效率：指令的执行速度要快；指令的使用频度要高；各类指令之间要有一定的比例
* 兼容性：在同一系列机内指令系统不变（可以适当增加）

#### CISC

(Complex Instruction Set Computer)	

增强指令功能，设置功能复杂的指令	

面向目标代码、高级语言和操作系统	

用一条指令代替一串指令

#### RISC

(Reduced Instruction Set Computer)	

只保留功能简单的指令	

功能较复杂的指令用子程序来实现

* 延时转移技术
* 指令取消技术
* 重叠寄存器窗口技术
* 指令流调整技术
* 以硬件为主固件为辅

## 存储系统

### 存储系统原理

![image-20231114153435848](imgs/26.png)

#### 存储系统的定义

* 两个或两个以上速度、容量和价格各不相同的存储器用硬件、软件、或软件与硬件相结合的方法连接起来成为一个存储系统。
* 这个存储系统对应用程序员是透明的，并且，从应用程序员看，它是一个存储器，这个存储器的速度接近速度最快的那个存储器，存储容量与容量最大的那个存储器相等，单位容量的价格接近最便宜的那个存储器。
* 虚拟存储器系统：对应用程序员透明
* Cache存储系统：对系统程序员以上均透明

![image-20231114162346705](imgs/32.png)

**虚拟存储系统**

由主存储器和硬盘构成

主要目的：扩大存储器容量

![image-20231114162421037](imgs/33.png)

**存储系统的容量**

* 要求：

  * 提供尽可能大的地址空间

  * 能够随机访问

* 方法有两种：

  * 只对系统中存储容量最大的那个存储器进行编址，其他存储器只在内部编址或不编址。

  * Cache存储系统。

* 另外设计一个容量很大的逻辑地址空间，把相关存储器都映射这个地址空间中。

  * 虚拟存储系统。

**存储系统的价格**

![image-20231114162803291](imgs/34.png)
$$
C=\frac{C_1 \cdot S_1+C_2 \cdot S_2}{S_1+S_2}
$$
**存储系统的速度**

![image-20231114163027416](imgs/35.png)

提高存储系统速度的两条途径：

* 提高命中率H。
  * 采用预取技术提高命中率
    * 方法：不命中时，把M2存储器中相邻多个单元组成的一个数据块取出来送入M1存储器中。
    * 计算公式$H^{\prime}=\frac{H+n-1}n$
    * 其中：H’是采用预取技术之后的命中率
    * H是原来的命中率
    * n为数据块大小与数据重复使用次数的乘积
* 两个存储器的速度不要相差太大。
* 其中：第二条有时做不到(如虚拟存储器)，这时，只能依靠提高命中率。

**存储系统的访问效率**
$$
e=\frac{T_1}{T}=\frac{T_1}{H\cdot T_1+(1-H)\cdot T_2}=\frac{1}{H+(1-H)\cdot\frac{T_2}{T_1}}=f(H,\frac{T_2}{T_1})
$$
访问效率主要与命中率和两级存储器的速度之比有关

**内存**

* RAM

  * DRAM

    ![image-20231114161215500](imgs/27.png)

  * Cache-SRAM (static RAM) made up of flip-flops (like Registers)

* ROM
  * PROM
  * EPROM
  * EEPROM

**外存**

* Magnetic Disk

  * RAID

  * Removable

* Solid State Drive (nowadays)

* Optical

  * CD-ROM
  * CD-Recordable (CD-R)

  * CD-R/W

  * DVD

* Magnetic Tape

**主要性能**

存储器的主要性能：速度、容量、价格。

* 速度用存储器的访问周期、读出时间、频带宽度等表示。
* 容量用字节B、千字节KB、兆字节MB和千兆字节GB等单位表示。
* 价格用单位容量的价格表示，例如：$C/bit。
* 组成存储系统的关键：把速度、容量和价格不同的多个物理存储器组织成一个存储器，这个存储器的速度最快，存储容量最大，单位容量的价格最便宜。

#### 存储系统的层次结构

![image-20231114161940074](imgs/28.png)

![image-20231114162001246](imgs/29.png)

存储层次工作原理：**Locality**

* 应用程序局部性原理: 给用户

  * 一个采用低成本技术达到的存储容量. （容量大，价格低）

  * 一个采用高速存储技术达到的访问速度.（速度快）

* Temporal Locality (时间局部性):

  * =>保持最近访问的数据项最接近微处理器

* Spatial Locality (空间局部性):

  * 以由地址连续的若干个字构成的块为单位，从低层复制到上一层

![image-20231114162208874](imgs/30.png)

![image-20231114162225091](imgs/31.png)

#### 存储系统的频带平衡

解决存储器频带平衡方法

* 多个存储器并行工作
* 设置各种缓冲存储器
* 采用存储系统

#### 并行访问存储器

![image-20231114163617974](imgs/36.png)

![image-20231114163635363](imgs/37.png)

#### 交叉访问存储器

[多体并行：高位/低位交叉编址-CSDN博客](https://blog.csdn.net/nuo_Shar/article/details/79048019)

##### 高位交叉访问存储器

* 主要目的：扩大存储器容量
* 实现方法：用地址码的高位部分区分存储体号
* 参数计算方法:
  * m: 每个存储体的容量， 
  * n: 总共的存储体个数， 
  * j: 存储体的体内地址，$\mathrm{j= 0, 1, 2, ..., m- 1}$
  * k: 存储体的体号，k=0, 1, 2, .., n-1
  * 存储器A的地址： $\mathbf{A}=\mathbf{m}\times\mathbf{k}+\mathbf{j}$
  * 存储器的体内地址： $\mathbf{A_i}=\mathbf{A}$ mod m
  * 存储器的体号$\quad\mathbf{A_k}=\left\lfloor\frac Am\right\rfloor$

##### 低位交叉访问存储器

* 主要目的：提高存储器访问速度
* 实现方法：用地址码的低位部分区分存储体号
* 参数计算:
  * m: 每个存储体的容量， 
  * n: 总共的存储体个数， 
  * j: 存储体的体内地址，$\mathrm{j= 0, 1, 2, ..., m- 1}$
  * k: 存储体的体号，k=0, 1, 2, .., n-1
  * 存储器A的地址： $\mathbf{A}=\mathbf{n}\times\mathbf{j}+\mathbf{k}$
  * 存储器的体内地址:$\quad\mathbf{A_j}=\left\lfloor\frac An\right\rfloor$
  * 存储器的体号:$A_k=A \mod n$

* n个存储体分时启动
  * 一种采用流水线方式工作的并行存储器
  * 每个存储体的启动间隔为$t=\left\lfloor\frac{Tm}n\right\rfloor$
  * 其中： 
  * Tm为每个存储体的访问周期
  * n为存储体个数

![image-20231114164447369](imgs/38.png)

#### 无冲突访问存储器

### 虚拟存储器

#### 虚拟存储器工作原理

把主存储器、磁盘存储器和虚拟存储器都划分成固定大小的页

* 主存储器的页称为实页
* 虚拟存储器中的页称为虚页

![image-20231121141158327](imgs/39.png)

[深入理解虚拟存储器（1:虚拟存储器概念与工作原理）-CSDN博客](https://blog.csdn.net/github_33873969/article/details/78460522)

#### 地址的映像和变换方法

三种地址空间

* 虚拟地址空间
* 主存储器地址空间
* 辅助地址空间

地址映像

把虚拟地址空间映象到主存地址空间

地址变换

在程序运行时，把虚地址变换成主存实地址

三种虚拟存储器

* 段式虚拟存储器

  **地址映象方法**：每个程序段都从0地址开始编址，长度可长可短，可以在程序执行过程中动态改变程序段的长度

  ![image-20231121142515910](imgs/40.png)

  **地址变换方法**：由用户号找到基址寄存器，读出段表起始地址，与虚地址中段号相加得到段表地址，把段表中的起始地址与段内偏移D相加就能得到主存实地址

  ![image-20231121142648106](imgs/41.png)

  段表中的段长和访问方式用来保护程序段

  * 可以根据程序段的**起始地址**和**段长**计算出本次访问主存储器的地址是否越界。

  * 访问方式可以指出本程序段是否需要保护和保护的级别。

  * 装入位如果表明该程序段不在主存中，段表的起始地址和访问方式字段可以用来存放该程序段在磁盘存储器中的起始地址，便于从磁盘把信息读到主存。

  外部碎片的消除

  * compaction

    Moving segments closer to zero to eliminate wasted space

    ![image-20231121143248395](imgs/42.png)

  * fit segments in existing holes

    [动态分区分配算法(First Fit，Next Fit，Best Fit，Worst Fit)-CSDN博客](https://blog.csdn.net/weixin_43886592/article/details/107581653)

    * Maintain a list of Addresses & Hole Size
    * algorithms
      * best fit: choose smallest hole
      * FIRST FIT: scan circularly & choose which fits first.

  主要优点

  * 程序的模块化性能好
  * 便于程序和数据的共享
  * 程序的动态链接和调度比较容易
  * 便于实现信息保护

  主要缺点

  * 地址变换所花费的时间长，两次加法。
  * 主存储器的利用率往往比较低。
  * 对辅存（磁盘存储器）的管理比较困难

* 页式虚拟存储器

  * 把虚拟地址空间划分为固定大小的块，每一块称为1页

  * 主存的地址空间也划分为同样大小的页

  * 为和磁盘存储器物理块大小配合，虚拟存储器大小指定为0.5kb的整数倍

  * 用户程序只需要将虚页号变换为实页号即可实现到主存实地址空间的映像

  ![image-20231121143927570](imgs/43.png)

  内部地址变换：多用户虚拟地址$A_v$变换成主存实地址A

  * 多用户虚拟地址中的页内偏移D直接作为主存实地址中的页内偏移d
  * 主存实页号p与它的页内偏移d直接拼接起来就得到主存实地址A

  ![image-20231121144120269](imgs/44.png)

  地址映像方法

  ![image-20231121144159777](imgs/45.png)

  地址变换方法

  ![image-20231121144220253](imgs/46.png)

  优点

  * 主存储器的利用率比较高。每个用户程序只有不到1页的浪费。
  * 页表相对比较简单。需保存的字段数比较少。
  * 地址变换的速度比较快。只需建立虚页和实页之间的联系即可。
  * 对磁盘的管理比较容易。一页的大小是磁盘快大小的整数倍

  缺点

  * 程序的模块化性能不好。一页可能多个程序或者部分程序。
  * 页表很长，需要占用很大的存储空间

* 段页式虚拟存储器

  用户按段写程序, 每段分成几个固定大小的页

  地址映像方法

  * 每个程序段在段表中占一行，
  * 在段表中给出页表长度和页表的起始地址，
  * 页表中给出每一页在主存储器中的实页号。

  ![image-20231121145440247](imgs/47.png)

  地址变换方法

  * 先查段表，得到页表起始地址和页表长度，
  * 再查页表找到要访问的主存实页号，
  * 把实页号p与页内偏移d拼接得到主存实地址

  ![image-20231121145528211](imgs/48.png)

* 外部地址变换

  保存和恢复故障点的现场，待故障处理完后返回断点继续执行程序

  * 采用硬件的缓冲寄存器，把执行该指令时的故障现场全部保存在缓冲寄存器中，等页面失效处理完，可以完整的恢复故障点还没有执行完的程序。
  * 只保护部分现场，如程序计数器、处理机状态字等，等页面失效结束，从头开始执行没有完成的指令。
  * 采用指令预判技术，对那些可能发生跨页执行的指令，如字符串指令等，在指令执行之前，就做页面失效处理，等该指令所需页面全部调入主存才开始执行该指令。

  每个程序有一张外页表，每一页或每个程序段，在外页表中都有对应的一个存储字

  ![image-20231121150640954](imgs/49.png)

#### 加快内部地址变换的方法

造成虚拟存储器速度降低的主要原因

* 要访问主存储器必须先查段表或页表，
* 可能需要多级页表

页表级数的计算公式
$$
g=\left\lceil\frac{\log2N\nu-\log2Np}{\log2Np-\log2Nd}\right\rceil
$$

* Nv为虚拟存储空间大小，
* Np为页面的大小，
* Nd为一个页表存储字的大小。

##### 目录表

基本思想：压缩页表存储容量，用一个小容量高速存储器存放页表，加快页表的查表速度

页表只为装入到主存的那些页面建立虚页号与实页号之间的对应关系

![image-20231121151105280](imgs/50.png)

地址变换过程

把多用户虚地址中U与P拼接，相联访问目录表。读出主存实页号p，把p与多用户虚地址中的D拼接得到主存实地址。如果相联访问失败，发出页面失效请求。

优点

* 与页表放在主存中相比，查表速度快

缺点

* 可扩展性比较差。
* 主存储器容量大时，目录表造价高，速度低

##### 快慢表

![image-20231121151633801](imgs/51.png)

快表TLB(Translation Lookaside Buffer)

* 小容量(几～几十个字)。
* 高速硬件实现。
* 采用相联方式访问

慢表

* 当快表中查不到时，从主存的慢表中查找。快表是慢表的部分副本。访问速度接近快表，存储容量是慢表的容量。
* 慢表按地址访问；用软件实现。

快表与慢表也构成一个两级存储系统。

主要存在问题：相联访问实现困难，速度低。

##### 散列函数

目的：把相联访问变成按地址访问

按地址查找信息，散列(Hashing)函数最快，对于快表就是要把多用户虚页号变成快表的地址：Ah＝H(Pv)

![image-20231121152630632](imgs/52.png)

* 把一个大得多的多用户虚页号Pv散列变成一个小的快表地址，必然有很多个多用户虚页号都变到相同的快表地址中，这种现象称为散列冲突。
* 为避免散列冲突，必须把多用户虚页号也加入到快表中，并且与主存实页号存放到同一个快表存储字中。
* 需要一个比较器，把快表中读出来的多用户虚页号与多用户虚地址中的虚页号进行比较。
  * 比较结果相等，继续正常进行主存的访问。
  * 比较结果不等，发生了散列冲突，需要查询主存中的慢表。

采用散列变换实现快表按地址访问

* 避免散列冲突：采用相等比较器
* 地址变换：相等比较与访问存储器同时进行

![image-20231121152959373](imgs/53.png)

##### inverted page tables反置页表

[反置页表(Inverted Page Table) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/195657513)

使用反置页表的话，所有进程共同使用一张页表，这张页表中的条目的数量和内存中物理的页框的数量是一样的。反置页表中的每个条目拥有以下字段：

* 页号
* 进程ID
* 控制位——包括valid位，dirty位，reference位，protection位和locking位。
* 链接指针——如果出现进程共享内存的情况，就会用到链接指针

![image-20231121153255138](imgs/54.png)

#### 页面替换算法及其实现

##### 页面替换发生时间

当发生页面失效时，要从磁盘中调入一页到主存。如果主存储器的所有页面都已经被占用，必须从主存储器中淘汰掉一个不常使用的页面，以便腾出主存空间来存放新调入的页面。

##### 评价页面替换算法好坏的标准

* 命中率要高，
* 算法要容易实现。

##### 页面替换算法的使用场合

* 虚拟存储器中，主存页面的替换，一般用软件实现。
* Cache中的块替换，一般用硬件实现。
* 虚拟存储器的快慢表中，快表存储字的替换，用硬件实现。
* 虚拟存储器中，用户基地址寄存器的替换，用硬件实现。
* 在有些虚拟存储器中，目录表的替换。

##### 主要页面替换算法

* 随机算法（RAND random algorithm）
  * 算法简单，容易实现。
  * 没有利用历史信息，没有反映程序的局部性。
  * 命中率低。
* 先进先出算法
  (FIFO first-in first-out algorithm)
  * 容易实现，利用了历史信息。
  * 没有反映程序的局部性。
  * 最先调入的页面，很可能也是要使用的页面。
* 近期最少使用算法(LFU least frequently used algorithm)：
  * 既充分利用了历史信息，又反映了程序的局部性实现起来非常困难。
* 最久没有使用算法(LRU least recently used algorithm)：
  * 把LFU算法中的“多”与“少”简化成“有”与“无”，实现比较容易
* 最优替换算法（OPT optimal replacement algorithm）：
  * 是一种理想算法，仅用作评价其它页面替换算法好坏的标准。
* 实际可能只有FIFO和LRU

一个程序共有5个页面组成，分别为P1-P5。在程序执行过程中，页面地址流如下

P1，P2，P1，P5，P4，P1，P3，P4，P2，P4

假设分配给这个程序的主存只有3个页面

![image-20231121153720342](imgs/55.png)

##### 堆栈型替换算法

![image-20231128144311331](imgs/56.png)

![image-20231128144451129](imgs/57.png)

堆栈型替换算法的命中率随分配给该程序的主存页面上升而单调上升

#### 提高主存命中率的方法

##### 影响因素

* 程序在执行过程中的页地址流分布情况。
* 所采用的页面替换算法。
* 页面大小。
* 主存储器的容量。
* 所采用的页面调度算法。

##### 页面大小与命中率的关系

* 假设At和At+1是相邻两次访问主存的逻辑地址$d=|A_t-A_{t-1}|$
* 如果d<Sp，随着Sp增大，At和At+1在同一页面的可能性增大，即命中率Ｈ随着页面大小Sp的增大而提高
* 如果d>Sp，At和At+1一定不在同一页面，Sp增大，主存页面数减少，页面替换频繁，命中率Ｈ随着页面大小Sp的增大而降低

![image-20231205153627110](imgs/58.png)

* 当Sp比较小的时候，前一种情况是主要的，Ｈ随着Sp的增大而提高。当Sp达到某一个最大值之后，后一种情况成为主要的，Ｈ随着Sp的增大而降低。
* 当页面增大时，造成的浪费也要增加。
* 当页面减小时，页表和页面表在主存储器中所占的比例将增加。

##### 主存容量与命中率的关系

主存命中率H随着分配给该程序的主存容量S的增加而单调上升

在S比较小的时候，H提高得非常快。随着S的逐渐增加，H提高的速度逐渐降低。当S增加到某一个值之后，H几乎不再提高

![image-20231205153804801](imgs/59.png)

##### 页面调度方式与命中率的关系

* 请求页式：当使用到的时候，再调入主存
* 预取式（分页式）：在程序重新开始运行之前，把上次停止运行前一段时间内用到的页面先调入到主存储器，然后才开始运行程序。
* 预取式的主要优点：
  可以避免在程序开始运行时，频繁发生页面失效的情况。
* 预取式的主要缺点：
  如果调入的页面用不上，浪费了调入的时间，占用了主存的资源。

### 高速缓冲存储器cache

![image-20231212140842042](imgs/60.png)

#### 基本工作原理

CPU将主存地址放入主存地址寄存器，通过主存——Cache地址变换部件将主存中的块号B变换成Cache的块号b，结果放到Cache地址寄存器，主存地址中的块内地址W直接作为Cache的块内地址。

![image-20231212140956682](imgs/61.png)

#### 地址映象与变换方法

**地址映象**

把主存中的程序按照某种规则装入到Cache中，并建立主存地址与Cache地址之间的对应关系

**选取地址映象方法的主要考量**

* 地址变换的硬件实现容易、速度要快。
* 主存空间利用率要高。
* 发生块冲突的概率要小。

**地址变换**

当程序已经装入到Cache之后，在程序运行过程中，把主存地址变换成Cache地址

##### 全相联映象及其变换

* 映象规则：主存的任意一块可以映象到Cache中的任意一块。
* 映象关系有Cb×Mb种。
* 采用目录表存放这种关系，目录表的容量为Cb，字长为Cache地址中的块号长度加主存地址中的块号长度，再加1位有效位。

![image-20231212141503742](imgs/62.png)

优点：

* 块的冲突率最小。
* Cache利用率最高。

缺点：

* 需要一个相联访问速度很快，容量为Cb的相联存储器（目录表），代价高。
* 相联比较所花费的时间会影响到Cache的访问速度

地址变换规则 硬件实现复杂

![image-20231212141805213](imgs/63.png)

没有命中：

* 利用主存地址去访问主存，将主存一个字内容送到CPU。

* 包括被访问字的一块内容替换到Cache中。

* 修改目录表中的主存块号字段，把当前的主存块号B写到目录表的存储字中。

* 有效位表示目录表中各个存储字是否有效。
  * 如果为1，表示目录表中主存块号B与Cache块号b建立的映像有效，b是B的正确副本。
  * 如果为0，表示B和b之间映像无效，或没有关系。

##### 直接映象及其变换

* 映象规则：主存储器中一块只能映象到Cache的一个特定的块中。

* Cache地址的计算公式：
  $$
  b=B\ mod\ C_b
  $$

  * b为Cache块号，
  * B是主存块号，
  * Cb是Cache块数。

* Cache地址与主存储器地址的低位部分完全相同

![image-20231212142259495](imgs/64.png)

* 主存块号B和Cache块号b完全相同。
* 体内地址完全相同。

**优点**

* 硬件实现很简单，不需要相联访问存储器
* 访问速度也比较快，实际上不需要进行地址变换

**缺点**

* 块的冲突率比较高。主存中多块都映像到Cache同一块中，又是常用块，Cache的命中率很低

地址变换过程

* 用主存地址中的块号B去访问区号存储器，把读出来的区号与主存地址中的区号E进行比较：
  * 比较结果相等，有效位为1，则Cache命中，否则该块已经作废。
  * 比较结果不相等，有效位为1，Cache中的该块是有用的，否则该块是空的。

![image-20231212142635126](imgs/65.png)

* 如果区号比较结果相等，有效位为0，表示Cache中这一块已经作废，把从主存读出来的新块按照Cache地址装入到Cache中，有效位置1。
* 如果区号比较结果不相等，有效位为0，表示该块是空的。主存读出块写入到Cache中，有效位置1，主存区号写入到区表存储器相应单元。
* 如果区号比较结果不相等，有效位为1，表示Cache中原来那块是有用的，必须将该块写回主存，才能将新块存入，把主存区号写到区号存储器的相应单元。

**提高cache速度的一种方法**

把区号存储器与Cache合并成一个存储器

![image-20231212143414005](imgs/66.png)

##### 组相联映象及其变换

* 映象规则：
  * 主存和Cache按同样大小划分成块和组。
  * 主存和Cache的组之间采用直接映象方式。
  * 在两个对应的组内部采用全相联映象方式。
* 组相联映象方式的优点：
  * 块的冲突概率比较低，
  * 块的利用率大幅度提高，
  * 块失效率明显降低。
* 组相联映象方式的缺点：
  * 实现难度和造价要比直接映象方式高。

![image-20231212143531117](imgs/67.png)

* 实现地址变换需要一个高速是小容量的存储器做成块表存储器。
* 采用地址访问和相联访问两种工作方式。块内相联，块间地址。
* 容量与Cache 的块数相等。字长为主存的区号、组内块号B、Cache块号b长度之和，加有效位和控制字段。

变换过程

1. 用主存地址中的组号G按地址访问块表存储器。
2. 把读出来的一组区号和块号与主存地址中的区号和块号进行相联比较。
   * 如果有相等的，表示Cache命中；
   * 如果全部不相等，表示Cache没有命中。

![image-20231212143908430](imgs/68.png)

提高Cache访问速度的一种方法：
用多个相等比较器来代替相联访问

![image-20231212143936413](imgs/69.png)

* 块内字数不多时，可以把块表和Cache合并成一个存储器。

* 组相联映像方式和直接映像方式相比，最明显的优点是块的冲突率大大降低，如组内有4块相联的组相联，主存的一块可以映射到4块中，直接映像只能映射到一块。
  * 块利用率大幅度提高，失效率明显下降。
  * 但组内需要比较，实现难度和造价较高。
* 组相联映像方式和全相联映像方式相比，实现起来还是要容易，而命中率相近。
  * 当每组的块容量Gb为1时，就是直接映像方式。
  * 当每组块容量Gb与Cache的块容量Cb相等时，就是全相联方式。
* 在Cache的容量和每块的大小确定后，选择每组的块容量Gb，和Cache的组容量Cg，即分配Cache地址中组号g和组内块号b的长度，可以优化Cache性能。
  * 块冲突率。
  * 块失效率。
  * 查表速度。
  * 实现的复杂性和成本。
  * 组内块容量越大，冲突率、失效率低，但查表慢、成本高。

##### 位选择组相联映象及其变换

* 地址映象规则：
  * 主存和Cache都按同样大小分块。
  * Cache在分块的基础上再分组。
  * 主存按照Cache的组容量分区，区块容量等于Cache内组容量。
  * 主存的块与Cache的组之间采用直接映象方式。
  * 主存中的块与Cache中组内部的各个块之间采用全相联映象方式。
* 与组相联映象方式比较：
  * 映象关系明显简单，实现起来容易。
  * 在块表中存放和参与相联比较的只有区号E。

![image-20231212144202801](imgs/70.png)

主存块只能到Cache中特定的组，在组内的位置随便

![image-20231212144228377](imgs/71.png)

##### 段相联映象及其变换

* 映象规则：
  * 主存和Cache都按同样大小分块和段。
  * 段之间采用全相联映象方式。
  * 段内部的块之间采用直接映象方式。
* 地址变换过程：
  1. 用主存地址中的段号与段表中的主存段号进行相联比较
  2. 如果有相等的，用主存地址的段内块号按地址访问Cache的段号部分。
  3. 把读出的段号s与主存地址的段内块号b及块内地址w拼接起来得到Cache地址。

![image-20231212144325762](imgs/72.png)

主存内块可以到Cache内任何一个段，但在到段之后只能在段内特定的位置。

**段相联映象方式的优缺点**

* 主要优点：
  * 段表比较简单，实现的成本低。
  * 例如：一个容量为256KB的Cache，分成8个段，每段2048块，每块16B。
  * 在段表存储器中只需要存8个主存地址的段号,
  * 而在块表中要存储8×2048＝16384个区号，
  * 两者相差2000多倍。
* 主要缺点：
  * 当发生段失效时，要把本段内已经建立起来的所有映象关系全部撤消。

#### Cache替换算法及其实现

* 使用的场合：
  * 直接映象方式实际上不需要替换算法。
  * 全相联映象方式的替换算法最复杂。
  * 主要用于组相联、段相联等映象方式中。
* 要解决的问题：
  * 记录每次访问Cache的块号。
  * 在访问过程中，对记录的块号进行管理。
  * 根据记录和管理结果，找出替换的块号。
* 主要特点：全部用硬件实现。

##### 轮换法及其实现

用于组相联映象方式中，有两种实现方法

###### 每块一个计数器

* 在块表内增加一个替换计数器字段。
* 计数器的长度与Cache地址中的组内块号字段的长度相同。

替换方法及计数器的管理规则：

* 新装入或替换的块，它的计数器清0，同组其它块的计数器都加“1”。
* 在同组中选择计数器的值最大的块作为被替换的块。

###### 每组一个计数器

替换规则和计数器的管理：

* 本组有替换时，计数器加“1”，
* 计数器的值就是要被替换出去的块号。

轮换法的优点：

实现比较简单，能够利用历史上的块地址流情况。

轮换法的缺点：

没有利用程序的局部性特点。

##### LRU算法及其实现

* 为每一块设置一个计数器
  * 计数器的长度与块号字段的长度相同

* 计数器的使用及管理规则：
  * 新装入或替换的块，计数器清0，同组中其它块的计数器加1。
  * 命中块的计数器清0，同组的其它计数器中，凡计数器的值小于命中块计数器原来值的加1，其余计数器不变。
  * 需要替换时，在同组的所有计数器中选择计数值最大的计数器，它所对应的块被替换。

**LRU算法的优缺点**

* 主要优点：
  * 命中率比较高，
  * 能够比较正确地利用程序的局部性特点，
  * 充分地利用历史上块地址流的分布情况，
  * 是一种堆栈型算法，随着组内块数增加，命中率单调上升。
* 主要缺点：
  * 控制逻辑复杂，因为增加了判断和处理是否命中的情况。  

##### 比较对法

* 一个两态的触发器可以记录两个块之间的先后顺序，多个块之间的先后顺序可以用多个两态触发器组合来实现。
* 以三个块为例，分别称为块A、块B、块C，共有3种组合。AB，BC，AC。
* 用TAB表示B块比A块更久没有被访问。3个块有6种排列。TAB，TBC，TAC，TAB，TBC，TAC

**表示方法**

表示块C最久没有被访问过，有两种可能 ：A，B，C或者B，A，C

![image-20231212150950100](imgs/73.png)

表示块A最久没有被访问过，有两种可能 ： B，C，A或者C，B，A

![image-20231212151020924](imgs/74.png)

表示块B最久没有被访问过，有两种可能 ： A，C，B或者C，A，B。

![image-20231212151040379](imgs/75.png)

每组3个块的比较对法

![image-20231212151118246](imgs/76.png)

每次访问之后要改变触发器的状态

* 在访问块A之后：TAB＝1，TAC＝1，触发器TBC没有关联。
* 在访问块B之后：TAB＝0，TBC＝1，触发器TAC没有关联。
* 在访问块C之后：TAC＝0，TBC＝0，触发器TAB没有关联。

**比较对法硬件需求量计算**

需要的触发器个数为：$C_{G_b}^2=\frac{G_b\cdot(G_b-1)}2$

与门个数为Gb

每个门的输入端个数为Gb-1

每组的块数比较多时, 采用分级办法实现。

* 所分级数越多，节省器件越多，器件延迟越长。
* 实质上是用降低速度来换取节省器件。

##### 堆栈法

堆栈法的管理规则：

* 把本次访问的块号与堆栈中保存的所有块号进行相联比较。
* 如果有相等的，则Cache命中。把本次访问块号从栈顶压入，堆栈内各单元中的块号依次往下移，直至与本次访问的块号相等的那个单元为止，再往下的单元直止栈底都不变。
* 如果没有相等的，则Cache块失效。本次访问的块号从栈顶压入，堆栈内各单元的块号依次往下移，直至栈底，栈底单元中的块号被移出堆栈，它就是要被替换的块号。

![image-20231212152416603](imgs/77.png)

每组4块的堆栈法逻辑图

![image-20231212152457077](imgs/78.png)

* 堆栈法的主要优点：
  * 块失效率比较低，因为它采用了LRU算法。
  * 硬件实现相对比较简单。
* 堆栈法的主要缺点：
  * 速度比较低，因为它需要进行相联比较。
* 堆栈法与比较对法所用触发器的比例

$$
\frac{G_b\cdot(G_b-1)}2:G_b\cdot\log_2G_b
$$

其中，Gb是Cache每一组的块数。

当Gb大于8时，堆栈法所用的器件明显少于比较对法。



Cache替换算法主要解决：

* 记录每次访问的块号，可以用寄存器，计数器。
* 管理好所记录的块号，便于找出被替换的块号。
* 根据记录和管理的结果，采用时序逻辑判断哪个块号即将被替换。
  * 轮换法找出最早访问的块号。其他三种是找出最久没有访问过的块号。

#### cache存储系统的加速比

##### 加速比与命中率的关系

Cache存储系统的加速比SP:
$$
S_p=\frac{T_m}{T}=\frac{T_m}{H\cdot T_c+(1-H)\cdot T_m}=\frac{1}{(1-H)+H\cdot\frac{T_c}{T_m}})=f(H,\frac{T_m}{T_c})
$$
其中：

* Tm为主存储器的访问周期，
* Tc为Cache的访问周期，
* T为Cache存储系统的等效访问周期，
* H为命中率。

提高加速比的最好途径是提高命中率



加速比 SP 能够接近于期望值是$S_{pmax}=\frac{T_m}{T_c}$

![image-20231212152925572](imgs/79.png)

##### Cache命中率与容量的关系

Cache的命中率随它的容量的增加而提高。

关系曲线近似表示为$H=1-\frac{1}{\sqrt S}$

![image-20231212153104732](imgs/80.png)

##### Cache命中率与块大小的关系

* 在组相联方式中, 块大小对命中率非常敏感。
* 块很小时，命中率很低。
* 随着块大小增加命中率也增加, 有一个极大值。
* 当块非常大时, 进入Cache中的数据可能无用。
* 当块大小等于Cache容量时, 命中率将趋近零。

![image-20231212153144404](imgs/81.png)

##### Cache命中率与组数的关系

* 在组相联方式中, 组数对命中率的影响很明显。
* 随着组数的增加，Cache的命中率要降低。
* 当组数不太大时(小于512), 命中率的降低很少。
* 当组数超过一定数量时, 命中率的下降非常快。

#### cache的一致性问题

正常情况下， Cache内容该是主存内容的部分副本，但有时会造成主存和Cache的内容不一致。造成Cache与主存的不一致的原因：

1. 由于CPU写Cache，没有立即写主存
2. 由于IO处理机或IO设备写主存

![image-20231212153249906](imgs/82.png)

##### Cache的更新算法

1. 写直达法，写通过法，WT(Write-through)
   * CPU的数据写入Cache时，同时也写入主存。
2. 写回法，抵触修改法，WB(Write-Back)
   * CPU的数据只写入Cache，不写入主存，仅当替换时，才把修改过的Cache块写回主存。

写回法与写直达法的优缺点比较

* 可靠性，写直达法优于写回法。
  * 写直达法能够始终保证Cache是主存的副本。
  * 如果Cache发生错误，可以从主存得到纠正。
* 与主存的通信量，写回法少于写直达法。
  * 对于写回法：
    * 大多数操作只需要写Cache，不需要写主存。
    * 当发生块失效时，可能要写一个块到主存。
    * 即使是读操作，也可能要写一个块到主存。
  * 对于写直达法：
    * 每次写操作，必须写、且只写一个字到主存。
    * 实际上：
      * 写直达法的写次数很多、每次只写一个字；
      * 写回法是的写次数很少、每次要写一个块。
* 控制的复杂性, 写直达法比写回法简单。
  * 对于写回法：
    * 要为每块设置一个修改位，而且要对修改位进行管理；
    * 为了保证Cache的正确性，通常要采用比较复杂的校验方式或校正方式。
  * 对于写直达法：
    * 不需要设置修改位；
    * 只需要采用简单的奇偶校验即可。由于Cache始终是主存的副本，Cache一旦有错误可以从主存得到纠正。
* 硬件实现的代价, 写回法要比写直达法好。
  * 对于写直达法：
    * 为了缩短写Cache流水段的时间，通常要设置一个小容量的高速寄存器堆（后行写数缓冲站），每个存储单元要有数据、地址和控制状态等3部分组成。
    * 每次写主存时，首先把写主存的数据和地址写到高速寄存器堆中。
    * 每次读主存时，要首先判断所读数据是否在这个高速寄存器堆中。
  * 写回法不需要设置高速缓冲寄存器堆。

##### 写cache的两种方法

* 不按写分配法：
  * 在写Cache不命中时，只把所要写的字写入主存。
  * 写直达法中采用不按写分配法
* 按写分配法：
  * 在写Cache不命中时，还把一个块从主存读入Cache。
  * 写回法中采用按写分配法

##### 解决cache与主存不一致的不要办法

1. 共享Cache法。能根本解决Cache不一致，共享Cache可能成为访问的瓶颈，硬件复杂。
2. 作废法。当某一处理机写局部Cache时，同时作废其他处理机的局部Cache。
3. 播写法。把写Cache的内容和地址放到公共总线上，各局部Cache随时监听公共总线。
4. 目录表法。在目录表中存放Cache一致性的全部信息。
5. 禁止共享信息放在局部Cache中。

#### cache的预取算法

1. 按需取。当出现Cache不命中时，才把需要的一个块取到Cache中。
2. 恒预取。无论Cache是否命中，都把下一块取到Cache中。
3. 不命中预取。当出现Cache不命中，把本块和下一块都取到Cache中。

主要考虑因素：

* 命中率是否提高，Cache与主存间通信量。
* 恒预取能使Cache不命中率降低75～85％。
* 不命中预取能使Cache不命中率降低30～40％。  

#### cache性能优化

##### 指标

* Hit rate: fraction found in that level
  * So high that usually talk about Miss rate
  * Miss rate fallacy: as MIPS to CPU performance, 
* Average memory-access time 	= Hit time + Miss rate x Miss penalty (ns)
* Miss penalty: time to replace a block from lower level, including time to replace in CPU
  * access time to lower level = f(latency to lower level)
  * transfer time: time to transfer block =f(bandwidth)
* Average memory-access time (AMAT)	= Hit time + Miss rate x Miss penalty
* Cache optimizations
  * **Reducing the miss rate**
  * **Reducing the miss penalty**
  * **Reducing the hit time**

降低未命中率

降低未命中惩罚

降低命中时间

##### 降低miss penalty

###### Multi-level Caches

###### Critical Word First and Early Restart

###### Priority to Read Misses over Writes

###### Merging Write Buffers

###### Victim Caches

###### Sub-block placement

##### 降低miss rates

###### Larger block size

###### Larger Caches

###### Higher associativity

###### Pseudo-associative caches

###### Compiler optimizations

##### Reducing Cache Miss Penalty or Miss Rate via Parallelism

###### Nonblocking Caches

###### Hardware Prefetching

###### Compiler controlled Prefetching

##### 降低hit time

###### Small and Simple Caches

###### Avoiding address Translation during Indexing of the Cache

### 三级存储系统

* 虚拟存储系统和Cache存储系统可同时存在
* 存储系统可以有多种构成方法
* 不同的构成只是实现技术不同

![image-20231212163329127](imgs/83.png)

![image-20231212163346679](imgs/84.png)

![image-20231212163406247](imgs/85.png)

存储系统组织方式

* 两个存储系统的组织方式：

  ![image-20231212163538219](imgs/86.png)

  * 又称为：物理地址Cache存储系统。
  * 目前的大部分处理机采用这种两级存储系统。

* 一个存储系统组织方式：

  ![image-20231212163554180](imgs/87.png)

  * 又称为：虚拟地址Cache存储系统。
  * 如Intel公司的i860等处理机采用这种组织方式。

* 全Cache系统：

  * 没有主存储器。
  * 由Cache和磁盘组成存储系统。

#### 虚拟地址cache

既有虚拟存储器又有Cache的系统：

* 虚拟存储器采用位选择组相联方式
* 虚拟存储器中的一页等于主存储器的一个区
* 用虚拟地址中的虚页号访问快表
  * 如果快表命中，把块表中的主存区号E与快表中的主存实页号P进行比较。
    * 若比较结果相等，则Cache命中。读出Cache的块号b，并与B、b、W拼接得到Cache地址。
    * 若Cache不命中，则用主存实页号P、及B和W拼接，得到主存实地址。

#### 全cache存储系统

* 建立存储系统的目的：获得一个速度接近Cache，容量等于虚拟地址空间的存储器。
  * 这个存储器如何构成，具体分成几级来实现，只是具体的实现技术而已。
  * 随着计算机硬件和软件技术的发展，存储系统的实现技术也在不断改变。
  * 最直接最简单的方法：用一个速度很高，存储容量很大的存储器来实现。

* 全Cache(all-Cache)是一种理想的存储系统。

![image-20231212163724701](imgs/88.png)



**重点**

1. 存储系统的定义及主要性能计算。

2. 并行存储器的工作原理。
3. 虚拟存储系统的工作原理。
4. 虚拟存储器中加快地址变换的方法。
5. 虚拟存储系统的页面替换算法。
6. Cache存储系统的地址映象及变换方法。
7. Cache存储系统的替换算法。
8. Cache存储系统的加速比。

## 输入输出系统

### 输入输出原理

通常把处理机与主存储器之外的部分统称为输入输出系统，包括**输入输出设备**、**输入输出接口**和输入输出软件等。
实际上，运算器、控制器、主存储器和总线等也要通过输入输出系统来管理。

#### 输入输出系统的特点

* 输入输出系统是处理机与外界进行数据交换的通道。
* 输入输出系统是计算机系统中最具多样性和复杂性的部分。
* 输入输出系统涉及到机、光、电、磁、声、自动控制等多种学科。
* 输入输出系统最典型地反映着硬件与软件的相互结合。
* 输入输出系统的复杂性隐藏在系统软件中，用户无需了解输入输出设备的具体细节。

![image-20231214190443537](imgs/94.png)

##### 异步性

采用**自治控制**的方法

* 输入输出设备通常不使用统一的中央时钟，各个设备按照自己的时钟工作，但又要在某些时刻接受处理机的控制。
* 处理机与外围设备之间，外围设备与外围设备之间能并行工作

##### 实时性

采用**层次结构**的方法

* 对于一般输入输出设备,如果处理机提供的服务不及时，可能丢失数据，或造成外围设备工作的错误。
* 对于实时控制计算机系统，如果处理机提供的服务不及时，可能造成巨大的损失，甚至造成人身伤害。
* 对于处理机本身的硬件或软件错误：如电源故障、数据校验错、页面失效、非法指令、地址越界等，处理机必须及时处理。
* 对不同类型的设备，必须具有与设备相配合的多种工作方式。

##### 设备无关性

采用**分类处理**的方法

* 独立于具体设备的标准接口。例如，串行接口、并行接口、SCSI（Small Computer System Interface）接口等。
* 计算机系统的使用者，在需要更换外围设备时，各种不同型号，不同生产厂家的设备都可以直接通过标准接口与计算机系统连接。
* 处理机采用统一的硬件和软件对品种繁多的设备进行管理。
* 某些计算机系统已经实现了即插即用技术。

#### 输入输出系统的组织方式

##### 自治控制

输入输出系统是独立于CPU之外的自治系统处理机与外围设备之间要有恰当的分工

##### 层次组织

![image-20231214190731398](imgs/95.png)

* 最内层是输入输出处理机、输入输出通道等。
* 中间层是标准接口。
* 标准接口通过设备控制器与输入输出设备连接。

##### 分类组织

* 面向字符的设备，如字符终端、打字机等
* 面向数据块的设备，如磁盘、磁带、光盘等

#### 基本输入输出

##### 程序控制输入输出方式

状态驱动输入输出方式、应答输入输出方式、查询输入输出方式、条件驱动输入输出方式

程序控制输入输出方式有**4个特点**

1. 何时对何设备进行输入输出操作受CPU控制。
2. CPU要通过指令对设备进行测试才能知道设备的工作状态。
   如：闲、准备就绪、忙碌等
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备，如终端、打印机等。

##### 中断输入输出方式

当出现来自系统外部，机器内部，甚至处理机本身的任何例外的，或者虽然是事先安排的，但出现在现行程序的什么地方是事先不知道的事件时，CPU暂停执行现行程序，转去处理这些事件，等处理完成后再返回来继续执行原先的程序

特点

1. CPU与外围设备能够并行工作。
2. 能够处理例外事件。
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备。

##### 直接存储器访问方式DMA

直接存储器访问方式(DMA：Direct Memory Access)，主要用来连接高速外围设备。如磁盘存储器，磁带存储器、光盘辅助存储器，行式打印机等。

![image-20231214191057909](imgs/96.png)

特点

1. 外围设备的访问请求直接发往主存储器，数据的传送过程不需要CPU的干预。
2. 全部用硬件实现，不需要做保存现场和恢复现场等工作。
3. DMA控制器复杂，需要设置数据寄存器、设备状态控制寄存器、主存地址寄存器、设备地址寄存器和数据交换个数计数器及控制逻辑等。
4. 在DMA方式开始和结束时，需要处理机进行管理。

工作流程：

1. 从设备读一个字节到DMA控制器中的数据缓冲寄存器中。
2. 若一个字没有装配满，则返回到上面；若校验出错，则发中断申请；若一个字已装配满，则将数据送主存数据寄存器。
3. 把主存地址送主存地址寄存器，并将主存地址增值。
4. 把DMA控制器内的数据交换个数计数器减１。
5. 若交换个数为0，则DMA数据传送过程结束，否则回到上面。

目前使用的DMA方式实际上有如下三种

1. 周期窃取方式
   * 在每一条指令执行结束时，CPU测试有没有DMA服务申请。
   * 借用CPU完成DMA工作流程。包括数据和主存地址的传送，交换个数计数器减1，主存地址的增值及一些测试判断等。
   * 周期窃取方式的优点是硬件结构简单，比较容易实现。
   * 缺点是在数据输入或输出过程种实际上占用了CPU的时间。
2. 直接存取方式
   * 整个工作流程全部用硬件完成。
   * 优点与缺点正好与周期窃取方式相反。
3. 数据块传送方式
   * 在设备控制器中设置一个比较大的数据缓冲存储器。设备控制器与主存储器之间的数据交换以数据块为单位，并采用程序中断方式进行。
   * 采用数据块传送方式的外围设备有软盘驱动器、行式打印机、激光打印机、卡片阅读机、绘图仪等。

### 中断系统

#### 中断源的组织

* 中断系统需要硬件和软件共同来实现。
* 引起中断的各种事件称为中断源。
* 中断系统的复杂性实际上主要是由中断源的多样性引起的。
* 中断源可以来自系统外部，也可以来自机器内部，甚至处理机本身。
* 中断可以是硬件引起的，也可以是软件引起的。
* 把各种各样的中断源分类、分级组织好，是中断系统的关键之一。

##### 中断源的种类

1. 由外围设备引起的中断。
   * 低速外围设备每传送一个字节申请一次中断；高速外围设备的前、后处理。
2. 由处理机本身产生的中断。
   * 如算术溢出，除数为零，数据校验错等。
3. 由存储器产生的中断。
   * 如地址越界、页面失效、访问存储器超时等。
4. 由控制器产生的中断。
   * 如非法指令、堆栈溢出、时间片到、切换到特权态。
5. 由总线产生的中断。
   * 输入输出总线出错,存储总线出错等。
6. 实时过程控制产生的中断。
7. 实时钟的定时中断。
8. 多处理机系统中，从其它处理机发送来的中断。
9. 程序调试过程中，由断点产生的中断。
10. 硬件故障中断
11. 电源故障中断。

##### 中断源的分类组织

* 中断源分类组织的目的：在响应中断后能尽快找到中断入口。
* 根据中断事件的紧迫程度，中断源工作速度、性质等进行分类
* 为每一类中断源分配一个硬件的中断入口，在进入这个入口之后，再通过软件找到具体的中断源。
* 可屏蔽中断与不可屏蔽中断，或称一般中断和异常中断。

>以IBM为例，中断源分为6类：
>
>1. 机器检验出错中断。由硬件或软件故障时产生。
>2. 程序性错误引起的中断。
>3. 访问管理程序中断。当用户程序执行访管指令引起的中断。
>4. 外部事件中断。
>5. 输入输出中断。
>6. 重新启动中断。处理机不能禁止这类中断

##### 中断优先级

* 安排中断优先顺序主要由下列因素来决定：
  * 中断源的急迫性。
  * 设备的工作速度。
  * 数据恢复的难易程度。
  * 要求处理机提供的服务量。
* 中断优先级与中断服务顺序
  * 要求：响应速度快，灵活性好。
  * 做法：由硬件排队器决定中断优先级，
* 通过软件设置中断屏蔽码改变中断服务顺序。

> 在IBM 370系列机中，把7类中断分为5个中断优先级，从高到低分别是:
>
> 1. 紧急的机器检验错误引起的中断。
> 2. 调用管理程序，程序性错误，可以抑制的机器检验错误引起的中断。
> 3. 外部事件引起的中断。
> 4. 外围设备的中断。
> 5. 重新启动引起的中断。

> DEC公司的机器，其优先级从高到低分别是
>
> 1. 总线错误引起的中断
> 2. 主存刷新中断
> 3. 指令错误引起的中断
> 4. 程序跟踪中断
> 5. 电源掉电中断
> 6. 在线停机中断
> 7. 在线事件中断(如实时钟等)
> 8. 外围设备中断
> 9. 用户程序中断

#### 中断系统的软硬件分配

有些功能必须用硬件实现，有的功能必须用软件实现，而大部分功能既可以用硬件实现，也可以用软件实现。

恰当分配中断系统的软硬件功能，是中断系统最关键问题。

主要考虑的两个因素：

* 中断响应时间：中断响应时间是一个非常重要的指标。
* 灵活性：硬件实现速度快，灵活性差；软件实现正好相反。

##### 中断处理过程

* 现行指令结束，且没有更紧急的服务请求。
* 关CPU中断。
* **保存断点**，主要保存PC中的内容。（**硬件**）
* 撤消中断源的中断请求。
* 保存硬件现场，主要是PSW及SP等。
* 识别中断源。
* 改变设备的屏蔽状态。
* **进入中断服务程序入口**。（**硬件**）
* 保存软件现场，在中断服务程序中使用的通用寄存器等。
* 开CPU中断，可以响应更高级别的中断请求。
* **中断服务**，执行中断服务程序。（**软件**）
* 关CPU中断。
* 恢复软件现场。
* 恢复屏蔽状态。
* 恢复硬件现场。
* 开CPU中断。
* **返回到中断点**。（**软件**）

**保存中断点**和**进入中断服务程序入口**，这两个功能相当于执行一条转子程序指令，因为中断发生在现行程序的什么地方是不确定的，不能由程序员来安排。

返回到中断点，通过执行一条中断返回指令来实现。

中断服务必须用软件实现，因为是“程序中断方式”

##### 中断响应时间

从中断源向处理机发出中断服务请求开始，到处理机开始执行这个中断源的中断服务程序时为止，这一段时间称为中断响应时间

**影响中断响应时间的因素**

1. 最长指令执行时间
   * 有些指令的执行时间很长，甚至无法预测。
2. 处理其它更紧急的任务所用时间
   * 如处理DMA请求等。
3. 从第一次关CPU中断到第一次开CPU中断所经历的时间
   * 中断系统的软件与硬件功能分配，主要就是要考虑这一段内要所的事情用软件来实现，还是用硬件来实现。
4. 通过软件找到中断服务程序入口所用时间
   * 主要是第1和第3两部分。其中，第1部分是指令系统设计时考虑的问题，在中断系统的设计中，主要考虑第3部分。

#### 中断源的识别方法

##### 识别中断源的查询法

* 所有中断源共用一条中断请求线
* 处理机响应中断后都进入同一个程序入口
* 用软件找出申请中断的中断源
* 主要优点：灵活性好。
* 主要缺点：速度慢。

![image-20231214193931096](imgs/97.png)

```assembly
INTR:	SKIP DZ, PRN  ；如果打印机DONE＝0，跳过下一条指令
JMP  PRINT    ；转入打印机的中断服务程序入口PRINT
SKIP DZ, KEY  ；测试键盘的DONE＝0？
JMP  KEYBORD  ；转入键盘的中断服务程序入口KEYBORD
SKIP DN, MNT  ；测试显示器的DONE＝1？
JMP  ERROR    ；所有中断源均没有请求中断服务
JMP  MONITOR  ；转显示器的中断服务程序入口MONITOR
PRINT: ……           ；打印机中断服务程序
RNTI          ；返回到中断点
KEYBORD: ……         ；键盘输入的中断服务程序
RNTI          ；返回到中断点
MONITOR: ……         ；显示器输出的中断服务程序
RNTI          ；返回到中断点
ERROR: ……           ；出错处理程序
RNTI          ；返回到中断点  
```



##### 软件排队链法

* 设置一个中断请求寄存器，每个中断源在其中占据一位，并且按照中断的优先级从高位到低的顺序排列。
* 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口，其过程与查询法相同。
* 在公共中断服务程序入口，用一条特殊指令读出中断请求寄存器中的内容，并根据读出的内容直接进入中断服务程序。
* 节省了用软件逐个寻找中断源的时间

```assembly
inta R1;中断请求寄存器中的内容读入R1
sbt R1,R2;找到发出请求的最高级中断源,存入R2
jmp @tab(R2);转向中断服务程序入口
tab:dev1;最高级中断服务程序入口地址
dev2

devn;最低级中断服务程序入口地址
```

##### 硬件排队链法

* 用硬件排队器和编码器，在所有请求中断服务的中断源中，找出具有最高优先级的中断源。
* 设置一个中断请求寄存器，每个中断源在其中中占据一位。
* 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口。
* 转入公共的中断服务程序后，用一条特殊指令直接读到所有请求中断服务的中断源中具有最高优先级的中断源编号。
* 特点：识别中断源的速度更快

![image-20231214194412254](imgs/98.png)

```assembly
INTA R1      ;发出请求的最高级中断源送R1
JMP @VTAB(R1);转向中断源的中断服务程序入口
TAB:	DEV1         ;最高级中断服务程序入口地址
DEV2         ;第二级中断服务程序入口地址
     　……
DENn         ;最低级中断服务程序入口地址
```

硬件排队器和编码器

![image-20231214194531879](imgs/99.png)

##### 中断向量法

* 在主存储器的固定区域中开辟出一个专用的中断向量区。
* 用硬件排队器和编码器在所有请求中断服务的中断源中，产生具有最高优先级的中断源编号。
* 隐含执行上面方法中的两条识别中断源的指令，直接通过硬件转向这个中断源的中断服务程序入口。
* 不需要进入公共中断服务程序，能够实现到中断程序的最快转移。



上面的2、3、4三种识别中断源的方法都属于串行排队链法

串行排队链法的优点：

* 识别中断源的速度比较快，特别是中断向量法。
* 实现比较简单，中断源与处理机的连线很少。

串行排队链法的缺点：

* 灵活性比较差，中断优先级是由硬件固定。不能由程序员通过软件修改。
* 可靠性比较差，排队链串行分布在各个中断源中。一个出错，都出错。

##### 独立请求法

* 各个中断源使用自己独立的中断请求线。每一根中断请求线在处理机中有固定的或可编程的中断优先级。
* 如果同时有多个中断源请求中断服务，通过仲裁线路立即选择具有最高优先级的中断源，并向它发出中断响应信号INIT，处理机就可以立即转入这个中断源的中断服务程序。
* 独立请求法实际上是把分布在各个中断源内的串行排队器都集中到处理机中，从而克服了串行排队链法可靠性差的缺点，但灵活性差的缺点仍然存在。

![image-20231214194706297](imgs/100.png)

识别中断源的分组独立请求法（应用于中断源很多时）

* 把独立请求法与串行排队链法结合起来。
* 中断源分组：组内采用串行排队链法，组间采用独立请求法。

![image-20231214194745196](imgs/101.png)

#### 中断现场的保存和回复

中断现场的保护和恢复分别是中断处理机过程开始和结束时必须执行的步骤，可以分为三类：

1. 程序计数器PC，必须由硬件来完成保存，可以保存在存储器固定单元或者堆栈。利用中断返回指令来恢复。
2. 当前程序状态的有关信息，包括：处理机状态字、堆栈指针、基址寄存器、中断屏蔽码等
   * 保存与恢复方法有：主存固定区域，压入系统堆栈、交换处理机状态字。也可以采用软件在中断服务程序中保存和恢复。
3. 软件现场：指在中断服务程序中被破坏的通用寄存器。一般采用软件来保存和恢复现场，指令系统给予适当支持。也有些处理机采用硬件来保存软件现场，如Sparc处理机。

#### 中断屏蔽

##### 设置中断屏蔽用处

1. 在中断优先级由硬件确定了的情况下，改变中断源的中断服务顺序。
2. 决定设备是否采用中断方式工作。
3. 在多处理机系统中，把外围设备的服务工作分配到不同的处理机中。

##### 中断屏蔽的实现方法

1. 每级中断源设置一个中断屏蔽位。
   * 中断屏蔽位可以分部在各个中断源中，也可以集中到处理机，如放到处理机的状态字中。
2. 改变处理机优先级
   * 中断优先级不仅在处理机相应中断源的中断服务请求时使用，而且为每个中断的中断服务程序也赋予同样的中断优先级。

##### 中断屏蔽位的方法和处理机优先级法两种方法的差别

1. 两者使用的概念不同。
   * 前者使用中断屏蔽，
   * 后者使用中断优先级。
2. 需要屏蔽码的位数不同。
   * 前者所需要的屏蔽位数比较多，
   * n：log2n
3. 可屏蔽的中断源数量和种类不同。
   * 前者可以任意屏蔽掉一个或几个中断源，
   * 后者只能屏蔽掉比某一个优先级低的中断源。

### 通道处理机

通道处理机的作用主要是在外围设备种类、数量很多的情况下把外围设备的管理工作从CPU中分离出来

处理机与外部设备的连接方式

* 直接连接
* 通道处理机
* 输入输出处理机

#### 通道的作用和功能

##### 作用

* 通道处理机能够负担外围设备的大部分输入输出工作，包括管理所有按字节传输方式工作的低速和中速外围设备，按数据块传输方式工作的高速设备。对DMA接口初始化，设备故障的检测和处理。
* 可以看作一台能够执行有限输入输出指令，并且能够被多台外围设备共享的小型DMA专用处理机。
* 在一台大型计算机系统中可以有多个通道，一个通道可以连接多个设备控制器，一个设备控制器又可以管理一台或者多台外围设备。形成典型的I/O系统四层结构。

##### 主要功能

1. 接受CPU发来的指令，选择一台指定的外围设备与通道相连接。
2. 执行CPU为通道组织的通道程序。
3. 管理外围设备的有关地址。
4. 管理主存缓冲区的地址。
5. 控制外围设备与主存缓冲区之间数据交换的个数。
6. 指定传送工作结束时要进行的操作。
7. 检查外围设备的工作状态，是正常或故障。
8. 在数据传输过程中完成必要的格式变换。

#### 通道的工作过程

1. 在用户程序中使用访管指令进入管理程序，由CPU通过管理程序组织一个通道程序，并启动通道。
2. 通道处理机执行通道程序，完成指定的数据输入输出工作。
3. 通道程序结束后再次调用管理程序进行处理。

每完成一次输入输出工作，CPU只需要两次调用管理程序

![image-20231214195837317](imgs/102.png)

![image-20231214195856661](imgs/103.png)

![image-20231214195910121](imgs/104.png)

![image-20231214195926524](imgs/105.png)

#### 通道的种类

![image-20231214195950798](imgs/106.png)

##### 字节多路通道

![image-20231214200045830](imgs/107.png)

* 为多台低中速的外围设备服务。
* 有多个子通道，每个子通道连接一个控制器。



* 字节交叉方式：可以有不同的工作方式，连接在通道上的各个设备轮流占有一个时间片传输字节，或者，不同设备在它所分得的时间片内与通道在逻辑上建立不同的传输连接。
* 成组方式：允许一个设备占用通道较长时间传输一组数据，或者设备与通道的连接可以根据需要维持到一组数据传输完成。
* 两种方式自动转换。通过超时机制控制。

##### 选择通道

![image-20231214200305811](imgs/108.png)

* 为高速外围设备服务
* 只有一个以成组方式工作的子通道
* 高速外围设备必须设置专门通道在一段时间单独为一台外围设备服务，不同时间可以选择不同设备。一旦选中，通道进入忙状态。直至数据传输结束。
* 只有一套完整硬件，逐个为物理连接的几台高速设备服务。

##### 数组多路通道

* 字节多路通道和选择通道的结合。
* 每次为一台高速设备传送一个数据块，并轮流为多台外围设备服务。
* 从磁盘存储器读出文件的的过程分为三步：
  1. 定位
  2. 找扇区
  3. 读出数据
* 数组多路通道的实际工作方式：
  * 在为一台高速设备传送数据的同时，有多台高速设备可以在定位或者在找扇区。
* 与选择通道相比，数组多路通道的数据传输率和通道的硬件利用都很高，控制硬件的复杂度也高。

#### 通道中的数据传送过程

##### 字节多路通道的数据传送过程

![image-20231214200454364](imgs/109.png)

##### 选择通道的数据传送过程

![image-20231214200534173](imgs/110.png)

##### 数组多路通道的数据传送过程

![image-20231214200555866](imgs/111.png)

#### 通道流量分析

通道流量：

单位时间内能够传送的最大数据量。又称通道吞吐率，通道数据传输率等。
通道最大流量：通道在满负荷工作状态下的流量。

##### 通道流量与连接在通道上的设备的数据传输率的关系

$$
f_{BYTE}=\sum_{i=1}^pf_i\\f_{SELETE}=\operatorname*{Max}_{i=1}^pf_i\\f_{BLOCK}=\operatorname*{Max}_{i=1}^pf_i
$$

##### 三种通道的最大流量计算公式

$$
\begin{aligned}
&f_{MAX.BYTE}=\frac{p\cdot n}{(T_S+T_D)\cdot p\cdot n}=\frac{1}{T_S+T_D}\text{字节/秒} \\
&\begin{aligned}f_{MAX.SELETE}&=\frac{p\cdot n}{(T_S/n+T_D)\cdot p\cdot n}=\frac{1}{T_S/n+T_D}\text{字节/秒}\end{aligned} \\
&f_{\textit{MAX BLOCK}} = \frac { p \cdot n }{ ( T _ S / k + T _ D ) \cdot p \cdot n }=\frac1{T_S/k+T_D}\text{字节/秒}
\end{aligned}
$$

为保证通道不丢失数据，通道的实际流量应不大于通道最大流量
$$
f_{\mathrm{BYTE}}\le f_{\mathrm{MAX}:\mathrm{BYTE}}\\ f_{\mathrm{SELETE}}\le f_{\mathrm{MAX}:\mathrm{SELETE}}\\f_\text{BLOCK}\le f_{\mathrm{MAX}:\mathrm{BLOCK}}
$$

### 输入输出处理机

![image-20231214201217394](imgs/112.png)

#### 输入输出处理机的作用

输入输出处理机除了能够完成通道处理机的全部功能之外，还具有如下功能：

1. 码制转换。
2. 数据校验和校正。
3. 故障处理。
4. 文件管理。
5. 诊断和显示系统状态。
6. 处理人机对话。
7. 连接网络或远程终端。

* 输入输出处理机还可以根据需要完成分配给它的其它任务，如数据库管理等。
* 除了具有数据的输入输出功能之外，还具有运算功能和程序控制等功能。
* 不仅能够执行输入输出指令，还能够执行算术逻辑指令和程序控制指令等，就象一般的处理机那样。

##### 通道处理机存在的问题

1. 每完成一次输入输出操作要两次中断CPU的现行程序。
2. 通道处理机不能处理自身及输入输出设备的故障。
3. 数据格式转换、码制转换、数据块检验等工作要CPU完成。
4. 文件管理、设备管理等工作，通道处理机本身无能为力。

##### 输入输出处理机的多种组织方式

1. 多个输入输出处理机从功能上分工。
2. 以输入输出处理机作为主处理机。
3. 采用与主处理机相同型号的处理机作为输入输出处理机。
4. 采用廉价的微处理机来专门承担输入输出任务。

#### 输入输出处理机的种类

##### 根据是否共享主存储器

1. 共享主存储器的输入输出处理机。
   CDC公司的CYBER，Texas公司的ASC，
2. 不共享主存储器的输入输出处理机。
   STAT-100巨型机

##### 根据运算部件和指令控制部件是否共享

1. 合用同一个运算部件和指令控制部件。
   造价低，控制复杂。如CDC-CYBER和ASC
2. 独立运算部件和指令控制部件。
   独立运算部件和指令控制部件已经成为主流。
   如B-6700大型机和STAT-100巨型机等。

#### 输入输出处理机实例

![image-20231214201444120](imgs/113.png)



**重点**

1. 了解三种基本输入输出方式的原理及特点。
2. 中断系统中的软硬件功能分配。
3. 中断优先级和中断屏蔽的原理及方法。
4. 通道中的数据传送过程与流量分析。
5. 输入输出处理机的作用及种类。

## scalar processor

只有标量数据表示和标量指令系统的处理机称为标量处理机
提高指令执行速度的主要途径

1. 提高处理机的工作主频
2. 采用更好的算法和设计更好的功能部件
3. 采用指令级并行技术

三种指令级并行处理机：

1. 流水线处理机和超流水线(Super-pipelining)处理机
2. 超标量(Superscalar)处理机
3. 超长指令字(VLIW:  Very Long Instruction Word)处理机

### 流水线原理

计算机的各个部分几乎都可以采用:

1. 指令的执行过程可以采用流水线，称为指令流水线。
2. 运算器中的操作部件，如浮点加法器、浮点乘法器等可以采用流水线，称为操作部件流水线。
3. 访问主存的部件可以采用访存部件流水线。多个计算机之间，通过存储器连接，也可以采用流水线，称为宏流水线。

#### 指令的重叠执行方式

##### 顺序执行方式

![image-20231212165551223](imgs/90.png)

一条指令的执行过程：取指令->分析->执行

执行n条指令所用的时间为
$$
T=\sum_{i=1}^n(t_{\text{ 取指令 }i}+t_{\text{分析 }i}+t_{\text{执行 }i})
$$

* 如每段时间都为t，则执行n条指令所用的时间为：T=3nt
* 主要优点：控制简单，节省设备。
* 主要缺点：执行指令的速度慢，功能部件的利用率很低。

重叠（Overlap）：在两条相近指令的解释过程中，某些不同解释阶段在时间上存在重叠部分。包括一次重叠、先行控制技术和多操作部件并行。 

一次重叠：把取指令操作隐含在分析、执行指令过程中，则在任何时候只允许上条指令“执行”与下条指令“分析”相重叠。T=（n+1）×t 

若各段时间不等时，有实际执行时间：
$$
T=t_{\text{分}1}+\sum_{i=2}^{n}[\max\{t_{\text{分}i},t_{\text{执}i-1}\}]+t_{\text{执}n}
$$

##### 一次重叠执行方式(一种最简单的流水线方式)

![image-20231214184707805](imgs/91.png)

如果两个过程的时间相等，则执行n条指令的时间为：$T=(1+2n)t$

主要优点：   

* 指令的执行时间缩短   
* 功能部件的利用率明显提高

主要缺点：    

* 需要增加一些硬件    
* 控制过程稍复杂

##### 二次重叠执行方式

把取第k+1条指令提前到分析第k条指令同时执行

如果三个过程的时间相等，执行n条指令的时间为$T=(2+n)t$

理想情况下同时有三条指令在执行

处理机的结构要作比较大的改变，必须采用先行控制方式

![image-20231214185015139](imgs/92.png)

采用二次重叠执行方式，必须解决两个问题：

1. 有独立的取指令部件、指令分析部件和指令执行部件

   独立的控制器：存储控制器、指令控制器、运算控制器

2. 要解决访问主存储器的冲突问题

   取指令、分析指令、执行指令都可能要访问存储器





![image-20231214185150935](imgs/93.png)

先行控制执行时间:
$$
T_{\text{先行}} = t _ {\text{分}1}+\sum_{i=1}^nt_{\text{执}i}
$$
多操作部件并行：采用有多个功能部件的处理机，把ALU的多种功能分散到几个具有专门功能的部件中，这些功能部件可以并行工作，使指令流出速度大大提高。 

### 流水线技术

* 空间并行性

  设置多个独立的操作部件

  多操作部件处理机

  超标量处理机

* 时间并行性

  采用流水线技术。

  不增加或只增加少量硬件就能使运算速度提高几倍流水线处理机

  超流水线处理机

#### 流水线的表示方法

连接图、时空图、预约表，主要考虑前两种

##### 连接图

![image-20231218152918849](imgs/114.png)

流水线的每一个阶段称为流水步、流水步骤、流水段、流水线阶段、流水功能段、功能段、流水级、流水节拍等。

一个流水阶段与另一个流水阶段相连形成流水线。指令从流水线一端进入，经过流水线的处理，从另一端流出

有些复杂指令 在执行阶段也采用流水线方式工作，称为操作流水线。

指令流水线

![image-20231218153041344](imgs/115.png)

一般4至12个流水段，**等于及大于8个流水段**的称为**超流水线处理机**

##### 时空图

采用“时空图”表示流水线的工作过程。在时空图中，横坐标表示时间，也就是输入到流水线中的各个任务在流水线中所经过的时间。当流水线中各个流水段的执行时间都相等时，横坐标被分割成相等长度的时间段。纵坐标表示空间，即流水线的每一个流水段 

![image-20231218153257774](imgs/116.png)

一个浮点加法器流水线的时空图(由求阶差、对阶、尾数加和规格化4个流水段组成)

![image-20231218153331196](imgs/117.png)

![image-20231218153434563](imgs/118.png)

* **建立时间**：在流水线开始时有一段流水线填入时间，使得流水线填满。
* **正常流动时间**：流水线正常工作，各功能段源源不断满载工作。
* **排空时间**：在流水线第一条指令结束时，其他指令还需要一段释放时间。

![image-20231218153534740](imgs/119.png)



###### 流水线的特点

1. 流水一定重叠，比重叠更苛刻。
2. 一条流水线通常有多个子过程。每个子过程称为流水线的“级”或“段”。其数目称为流水线的“深度”。
3. 每段有专用功能部件，各部件顺序连接。
4. 流水线有建立时间、正常满载时间、排空时间。另外，流水线需要有“通过/装入时间”（第一个任务流出结果所需的时间），在此之后流水过程才进入稳定工作状态，每一个时钟周期（拍）流出一个结果。
5. 流水线每一个功能段部件后面都要有一个缓冲寄存器，或称为锁存器，其作用是保存本流水段的结果，如图8所示。由于流水线中每一个流水段的延迟时间不可能绝对相等，再加上电路的延迟时间及时钟等都存在偏移，因此流水段之间传送任务时，必须通过锁存器。
6. 流水线中各功能段的时间应尽量相等，否则将引起堵塞、断流，这个时间一般为一个时钟周期（拍） 。要求流水线的时钟周期不能快于最慢的流水段。另一方面，执行时间长的一个流水段将成为整个流水线的瓶颈，此时流水线中的其他功能部件就不能发挥作用。因此瓶颈问题是流水线设计中必须解决的问题。
7. 只有连续不断地提供同一种任务时才能发挥流水线的效率。例如，要使浮点加法器流水线充分发挥作用，需要连续提供浮点加法运算。只有流水线完全满载时，整个流水线的效率才能得到充分发挥。
8. 给出指标如最大吞吐率，为满负载最佳指标。

![image-20231218153828898](imgs/120.png)

###### 流水的分级分类

**分级**：（处理的级别分类）

* 部件级：将复杂的算逻运算组成流水工作方式； 
* 指令级：把一条指令解释过程分成多个子过程 ；
* 处理机级：每个处理机完成某一专门任务，各个处理机所得到的结果需存放在与下一个处理机所共享的存储器中

**其他分类**

* 功能：单功能流水线（如CRAY-1）、多功能流水线   （如TI-ASC）
* 工作方式：静态流水线、动态流水线
* 连接方式：线性、非线性
* 处理数据：标量流水、向量流水



#### 建立流水线

* 每一阶段添加锁存器
  * 在阶段转变时，一个锁存器存储临时的寄存器值
  * 锁存器由时钟控制和阶段同步
    * 每个阶段同时将其寄存器信息传递到下一个阶段（在每个时钟脉冲的开头）
    * 注意：锁存器会造成轻微延迟，因此时钟周期时间可能会略有延长
  * 锁存器由它们连接的阶段表示，例如 IF/ID、ID/EX
* 利用锁存器、合适的时机和控制建立流水线
  * 每一阶段拥有硬件
    * 我们最多可以同时执行 5 条指令，其中每条指令都处于 5 个阶段之一
  * 需要5轮来完成任一指令
    * 如果没有流水线，一个存储或一个分支可以分 4 个阶段完成
  * 但是，由于重叠，我们可以在 5 个周期内完成多达 5 条指令



MIPS流水线

![image-20231218155044290](imgs/121.png)



#### 流水线冒险

[关于流水线的三种冒险 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/447682231)

流水线中的**相关**是指相邻或相近的两条指令因存在某种关联，后一条指令不能在原指定的时钟周期开始执行。

##### 数据冒险

当指令在流水线中重叠执行时，后面的指令需要用到前面的指令的执行结果，而前面的指令尚未写回导致的冲突，称为数据冒险（也称为**数据相关性**）

相关性是程序的一个属性
相关性的存在表明存在潜在的危险，但实际危险和任何失速的长度是管道的属性
数据相关性的重要性

1. 表示危险的可能性
2. 确定必须计算结果的顺序
3. 设定了可以利用的并行度的上限

用硬件方案以避免危险



* 当管道中任何一对指令之间出现相关性以导致重叠时，就会发生数据危害
* 如果一对指令共享相同的寄存器或存储器位置，则可能会发生这种情况

三种数据冒险

###### RAW

先读后写

ADD R1, R2,R3
SUB R4, R5,R1

第一条指令写入R1

第二条指令读入R1

造成先读后写

有针对存储器RAW和针对寄存器RAW两种

![image-20231218170612822](imgs/128.png)

* 后推法：停顿后继指令的运行，直到前面指令结果生成；（不同拍之间）（R或M相关）

* 相关专用通路法：执行结果除写寄存器外，可直接送到ALU的操作数保存栈中。（R相关）

  ![image-20231218170746842](imgs/129.png)

* 同一拍中，采用推后读、提前写的方法 （R或M相关），对整个流水线来说，一个时钟周期分成前后两部分，于是可将ID流水段中读寄存器堆的操作安排在后半周期，而将WB流水段中写寄存器堆的操作安排在前半周期。 

* 装载延迟则采用联锁硬件检测，并使流水线停顿，直到相关消除。（RISC特有）流水线中还采用一种装入延迟的方法解决数据相关冲突。

  ![image-20231218170920635](imgs/130.png)

  ![image-20231218170941365](imgs/131.png)

* 异步流动法：让流水线中相关指令的后续不相关指令先执行，自动消除相关。



下面两种相关只有在异步流动流水线中才会产生。

使用动态调度方法检测和处理相关

###### WAR

先写后读

ADD R3, R2,R1
SUB R1, R4,R5

第一条读入R1

第二条写入R1

可能会先写后读

这种相关仅出现在这样的流水线中：
有些指令是在流水线的后部读源操作数，而有些指令则是在流水线的前部写结果。

MIPS流水线中不会发生这种相关；读在先（ID），写在后（WB））
这种相关很少发生；因为流水线一般是先读操作数，后写结果）
复杂指令可能导致这种相关。

###### WAW

ADD R1, R2,R3
SUB R1, R4,R5

第一条写入R1

第二条写入R1

先第二条后第一条写

这种相关仅出现在这样的流水线中：

*  流水线中有多个段可以进行写操作
* 当某条指令在流水线中暂停时，允许其后的指令继续向前流动。

MIPS整数流水线中不会发生这种相关   （仅在WB段进行写操作）





![image-20231218170225781](imgs/127.png)

第二-第四条指令发生RAW



##### 结构冒险

当一条指令需要的硬件部件还在为之前的指令工作，而无法为这条指令提供服务，那就导致了结构冒险。（这里结构是指硬件当中的某个部件、也称为**资源冲突**）

###### 同时读写存储器

如果指令和数据放在同一个存储器中，则不能同时读存储器

![](imgs/122.png)

**解决方案1**：我们有一个方便又简便的方法，即流水线停顿（stall），产生空泡（bubble）

![image-20231218163626685](imgs/126.png)

![](imgs/123.png)

* Insert a “bubble” into the pipeline to prevent 2 writes at the same cycle

当一条指令被暂停时，暂停在其后发射（流出）的指令，但继续执行在其前发射的指令。

虽然流水线停顿能用来解决各种冒险，但它的效率低下，应尽量避免

**解决方案2**：Delay R-type’s Write by One Cycle延迟一轮

Mem stage is a NOP stage: nothing is being done

**解决方案3**：在存储器中设置单独的指令高速缓存和数据高速缓存。（要强调的在计算机中主存储器也就是内存是统一存放指令和数据的，这也是冯诺依曼结构的要求，只是在CPU当中的一级高速缓存会采用指令和数据分别存放的方式）

![](imgs/124.png)

###### 同时读写寄存器

![](imgs/125.png)

前半个周期写，后半个周期读，并且设置独立的读写端口

结构冒险在设计处理器时就考虑并解决

A structural hazard can always be avoided by adding more hardware to design



解决存储器争用冲突的其他办法是：

* 如果指令和数据放在同一个存储器，可使用双端口存储器，其中一个端口存／取数据，另一个端口取指令。
* 设置两个存储器，其中一个作为数据存储器，另一个作为指令存储器。

上述两种方案中，取指令和访问(存／取)数据可以并行进行，不会发生结构相关。



指令相关

由当前指令产生后续指令，即指令可修改引起。

解决办法：

指令不允许修改；

把新指令作为“执行”指令的操作数，使指令相关变成数据相关。

##### 控制冒险

如果现在想要执行哪条指令，是由之前指令的运行结果决定，而现在那条之前指令的结果还没产生，就导致了控制冒险（实际上就是riscv的跳转指令引起的，跳转指令要经过2个周期后才会出现**跳转结果**）

流水线的**控制相关**是因为程序执行转移类指令而引起的相关。转移类指令如无条件转移、条件转移、子程序调用、中断等，它们属于分支指令，执行中可能改变程序的方向，从而造成流水线断流。

数据相关影响到的仅仅是本条指令附近少数几条指令，所以称为**局部相关**。而控制相关影响的范围要大得多，它会引起程序执行方向的改变，使流水线损失更多的性能，所以称为**全局相关**。

控制相关会使流水线的连续流动受到破坏。当执行条件转移指令时，有两种可能结果：

1. 如发生转移，将程序计数器PC的内容改变成转移目标地址；
2. 如不发生转移，只是将PC加上一个增量，指向下一条指令的地址

控制相关无需保存

两个对程序正确性重要的是异常行为和数据流

![image-20231218195631012](imgs/135.png)

###### stall

![image-20231218195807046](imgs/136.png)

插入空泡

wait until decision is clear

直到分支干净

图中浪费两轮

###### prediction

![image-20231218200312807](imgs/137.png)

**加快和提前形成条件码**

对转移指令的条件码，部分可提前生成；

加快循环内条件码形成。

对一般条件转移指令，转移条件码是由上一条运算型指令产生的。对于大多数运算类指令，可以在实际运算之前或运算中间就能产生条件码，不必等到运算结束后。    

例如乘法或除法指令，两个源操作数符号相同，结果为正，符号相反，结果为负；两个源操作数中有一个为0，则乘积为0；被除数为0，则商为0；除数为0，则除法结果溢出。因此，只要比较两个操作数的符号或阶码，就能确定运算结果的正负号，是否为0，是否溢出。对加减法来说，运算结果的正负号，是否为0，是否溢出，也能提前得知。 

* 预测分支失败
  * 流水线继续照常流动，就像没发生什么似的。
  * 在知道分支结果之前，分支指令后的指令不能
  * 改变机器状态，或者改变了之后能够回退。
  * 若分支失败，则照常执行；否则，从转移目标处开始取指令执行。
* 预测分支成功
  * 假设分支转移成功，并开始从分支目标地址处取指令执行。
  * 起作用的前题：先知道分支目标地址，后知道分支是否成功。
  * 对MIPS流水线没有任何好处。

###### double buffer

硬件上设置两个指令缓冲栈

当指令分析器分析到条件转移指令时，指令缓冲栈A按照转移不成功的方向预取指令，指令缓冲栈B按照转移成功的方向预取指令。当指令执行部件产生转移条件码时，如果转移不成功，则分析指令缓冲栈A中的指令；如果转移成功，则分析指令缓冲栈B中的指令，如图26(a)所示。

![image-20231218200509021](imgs/138.png)

###### delayed branch

![image-20231218200536503](imgs/139.png)

延迟转移技术由编译程序重排指令序列来实现。其基本思想是从逻辑上“延长”转移指令的执行时间，即发生“转移成功” 时并不排空指令流水线，而是让紧跟在转移指令I之后已进入流水线的少数几条指令继续完成，如果这些指令是与转移指令I结果无关的有用指令，那么延迟损失时间就可以有效地利用。 

所有的顺序后继指令构成“延迟转移槽”指令(一般情况下，n＝1)。无论转移成功与否，流水线都会执行这些指令。具有“延迟转移槽”的流水线时空图如图所示。

从时空图27看出，基于“延迟转移”方法，无论转移成功与否，其流水线时空图均相同，流水线中均没有插入暂停周期，从而极大地降低了流水线的转移损失。事实上，处于转移延迟槽中的指令“填补”了流水线原来所必须插入的暂停周期。



在哪里获得指令来填充分支延迟槽?

* 分支指令前
* 从目标地址:只有当分支采用时才有价值
* 从失败处:只有当分支不被采用时才有价值
* 取消分支允许更多的插槽被填充

延迟分支方法对比

| 调 度  策 略 | 对调度的要求                                                 | 什么情况下起作用？                                   |
| ------------ | ------------------------------------------------------------ | ---------------------------------------------------- |
| 从  前 调 度 | 被调度的指令必须与分支无关                                   | 任何情况                                             |
| 从目标处调度 | 必须保证在分支失败时执行被调度的指令不会导致错误。有可能需要复制指令。 | 分支成功时  （但由于复制指令，有可能会增大程序空间） |
| 从失败处调度 | 必须保证在分支成功时执行被调度的指令不会导致错。             | 分支失败时                                           |

###### 猜测方法

选取发生概率较高的分支为猜测方向，运行但不写回结果。若猜对，继续执行；否则,作废猜测方向的执行，返回实际转移处。

**如何提高猜测命中率**

* 静态猜测法：猜测不成功方向。

  由程序员和编译程序把发生概率高的分支安排在猜测方向。

* 动态猜测法：根据转移历史猜测

  硬件要求：增设转移目标缓冲器BTB。

###### 动态分支预测

[计算机体系结构学习（5）——分支预测 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/561643046)

* Static Branch Prediction 
* 1-bit Branch-Prediction Buffer
* 2-bit Branch-Prediction Buffer
* Correlating (Two-level) Branch Prediction Buffer
* Tournament Branch Predictor
* Branch Target Buffer
* Integrated Instruction Fetch Units
* Return Address Predictors

1. 只有1个预测位的分支预测缓冲 

   * 索引：分支指令地址的低位。

   * 存储区：1位的分支历史记录位，又称为预测位，
                 记录该指令最近一次分支是否成功。

   * “0”记录分支不成功 

     “1”记录分支成功

   * 状态转换图

     ![image-20231218202208655](imgs/140.png)

   * 分支预测缓冲技术包括两个步骤 

     * 分支预测

       如果当前缓冲记录的预测位为“1”，则预测分支为成功；如果预测位为“0”，则预测分支为不成功。

     * 预测位修改

       如果当前分支成功，则预测位置为“1”；如果当前分支不成功，预测位置为“0”。 

   * 分支预测错误时，预测位就被修改，并且需要恢复现场，程序从分支指令处重新执行。 

     ![image-20231218202825906](imgs/141.png)

   * 缺点：只要预测出错，往往是连续两次而不是一次。

   * 解决方法：采用两个预测位的预测机制。
     在两个预测位的分支预测中，更改对分支的预测
     必须有两次连续预测错误。

     ![image-20231218203453946](imgs/142.png)

2. n位分支预测缓冲

   * 采用n位计数器，则计数器的值在0到2n-1之间：
     当计数器的值大于或等于最大值的一半（$2^n-1$）时，
     预测下一次分支成功；否则预测下一次分支不成功。
   * 预测位的修改和两位预测时相同：
     当分支成功时计数器的值加1，不成功时减1。
   * 研究表明：n位分支预测的性能和两位分支预测差不多，因而
     大多数处理器都只采用两位分支预测



**实现方法**

两个关键问题

* 记录转移历史信息
* 根据所记录的转移历史信息来预测转移的方向

1. 使用BHT的转移预测

   当执行转移指令时，转移成功或转移失败的信息可记录在一个所谓的“转移历史表”BHT中。BHT是一个小容量的高速Cache。

   为了取得好的预测效果，又便于硬件实现，通常用2位计数器来记录最近二次转移是否成功的状态信息。图30示出了转移预测的状态转换图：每一个圆圈表示一种状态，分别用二进制数字10、11、01、00来表示；圆圈中的汉字表示在该状态下执行一条转移指令时将预测“转移取”指令或是“顺序取”指令；圆圈外的有向线段表示转移指令实际执行后状态位的变化方向。从这个状态转换图我们看到：在改变一次预测方向后，如果连续两次预测错误，则必定会改变预测方向。 

   ![image-20231219102551694](imgs/143.png)

2. 使用BTB的转移预测

   Pentium处理机中使用了转移目标缓冲栈BTB作为转移预测策略。支持这种策略的也是一个内部cache，其结构类似于图31所介绍的BHT结构，只不过每项的转移指令字段现在改为转移指令地址字段，如图32(a)所示。BTB是一个4路组相联的Cache，共有256行。转移指令地址(高24位)字段即为该项的标记(tag)，以转移指令地址的低8位为行索引。每项有2位历史状态位，记录最近执行该转移指令的历史，即以该转移指令的过去行为来猜测它的将来行为。每次转移指令执行完毕，依据预测是否正确要相应地修改历史位。历史位的使用和修改规则如图32(b)所示。将它与图30(a)相对照，不难发现BTB的预测更倾向于转移取。进入BTB的新基初始设置历史位为11状态

   ![image-20231219102633023](imgs/144.png)

   ![image-20231219102651071](imgs/145.png)

   每当Pentium流水线D1段译码出一条转移指令，控制逻辑将检索BTB，确定是否有该“转移指令地址”的相应项。如果cache未命中，则预测该转移指令为顺序取；如果命中，此项的历史位用于预测该转移指令应是“转移取”还是“顺序取”。若是顺序取，则继续由I-cache预取指令送至原先使用的一个预取缓冲栈。若是预测为转移取，则原先使用的预取缓冲栈立即冻结，依BTB相应表项给出的转移目标地址，由I-cache预取目标路径的指令序列送至另一个预取缓冲栈。因检索BTB和预取指令都是cache访问，故能在D1段同一时间内完成。因此，当转移指令Ib出现在D1段并被预测为转移取且I-cache也命中的话，转移目标处的最初两条指令It，It+1已及时出现在流水线上，没有任何延迟损失

   用2位二进制数记录实际转移状态(历史位)，高位为1时预测转移发生，高位为0时预测转移不发生。

   ![image-20231219102759012](imgs/146.png)

3. 使用BTIB的转移预测

   当转移指令在指令分析部件中译码时，转移不成功方向上的指令已经被预取到指令缓冲栈中，或者已经存放在I-cache中。为了能够在转移成功方向上也预取一部分指令，可以把图32(a)中的“转移目标地址”部分改为存放转移目标地址之后的n条指令。这种预测策略称为转移目标指令缓冲栈BTIB，它也是一个内部Cache，项逻辑结构如图33所示。它的工作原理、预测转移方向的规则、修改历史位的方法与BTB方法相类似。 

   ![image-20231219102855613](imgs/147.png)



猜测的后续处理

分支现场的保护及恢复

* 采用后援寄存器保存可能被破坏的状态；
* 猜测执行只完成译码、取操作数或执行，但不写结果。

预防猜不中时的加速处理：

预取猜测方向的另一方向的前几条指令，放到缓冲器中，加速猜不中时回头速度。

###### 精确中断与非精确中断

* 精确中断
  * 如果流水线可以控制使得引起异常的指令前序指令都执行完，故障后的指令可以重新执行，则称该流水线支持精确中断
  * 按照指令的逻辑序处理异常
  * 理想情况，引起故障的指令没有改变机器的状态
  * 要正确的处理这类异常请求，必须保证故障指令不产生副作用
* 在有些机器上，浮点数异常
  * 流水线段数多，在发现故障前，故障点后的指令就已经写了结果，在这种情况下，必须有办法处理。
  * 很多高性能计算机，Alpha 21164，MIPS R10000等支持精确中断，但精确模式要慢10+倍，一般用在代码调试时，很多系统要求精确中断模式，如IEEE FP标准处理程序，虚拟存储器等。
* 精确中断对整数流水线而言，不是太难实现
  * 指令执行的中途改变机器的状态
  * 例如IA-32 的自动增量寻址模式

![image-20231219103352920](imgs/148.png)

处理中断4种可能的办法

* 方法1：忽略这种问题，当非精确处理
  * 原来的supercomputer的方法
  * 但现代计算机对IEEE 浮点标准的异常处理，虚拟存储的异常处理要求必须是精确中断。
* 方法2：缓存操作结果，直到早期发射的指令执行完
  * 当指令运行时间较长时，Buffer区较大
  * Future file  (Power PC620 MIPS R10000)
    * 缓存执行结果，按指令序确认
  * history file  (CYBER 180/990)
    * 尽快确认
    * 缓存区存放原来的操作数，如果异常发生，回卷到合适的状态
* 方法3：以非精确方式处理，用软件来修正
  * 为软件修正保存足够的状态
  * 让软件仿真尚未执行完的指令的执行
  * 例如
    * Instruction 1 – A 执行时间较长，引起中断的指令
    * Instruction 2, instruction 3, ….instruction n-1 未执行完的指令
    * Instruction n    已执行完的指令
    * 由于第n条指令已执行完，希望中断返回后从第n+1条指令开始执行，如果我们保存所有的流水线的PC值，那么软件可以仿真Instruction1 到Instruction n-1 的执行
* 方法4：暂停发射，直到确定先前的指令都可无异常的完成，再发射下面的指令。
  * 在EX段的前期确认（MIPS流水线在前三个周期中）
  * MIPS R2K to R4K 以及Pentium使用这种方法

#### 流水线的分类

##### 线性与非线性流水线

* 流水线的各个流水段之间是否有反馈信号
* 线性流水线(Linear Pipelining)每个流水段都流过一次，且仅流过一次
* 非线性流水线(Nonlinear Pipelining)在流水线的某些流水段之间有反馈回路或前馈回路
* 线性流水线能够用流水线连接图唯一表示非线性流水线必须用流水线连接图与流水线预约表等共同表示

一种简单的非线性流水

![image-20231219104036534](imgs/149.png)

##### 流水线级别分类

###### 处理机级流水线

又称为指令流水线 (Instruction Pipelining)，例如：在采用先行控制器的处理机中，各功能部件之间的流水线

![image-20231219104143397](imgs/150.png)

###### 部件级流水线

把处理机的算术逻辑部件分段，使得各种数据类型的操作能够进行流水。
如浮点加法器流水线

![image-20231219104251086](imgs/151.png)

###### 宏流水线

每个处理机对同一个数据流的不同部分分别进行处理，它是指由两个以上的处理机串行地对同一数据流进行处理，每个处理机完成一项任务。

![image-20231219104335644](imgs/152.png)

##### 单功能与多功能流水线

###### 单功能流水线

只能完成一种固定功能的流水线

Cray-1计算机中有12条；

YH-1计算机有18条；

Pentium有一条5段的定点和一条8段的浮点流水线；

PentiumⅢ有三条指令流水线，其中两条定点指令流水线，一条浮点指令流水线。

###### 多功能流水线

流水线的各段通过不同连接实现不同功能

Texas公司的ASC计算机中的8段流水线，能够实现：定点加减法、定点乘法、浮点加法、浮点乘法、逻辑运算、移位操作、数据转换、向量运算等。

![image-20231219104636204](imgs/153.png)

##### 静态流水线与动态流水线

###### 静态流水线

同一段时间内，多功能流水线中的各个功能段只能按照一种固定的方式连接，实现一种固定的功能。

只有连续出现同一种运算时，流水线的效率才能得到充分的发挥。

![image-20231219104743632](imgs/154.png)

只有当进入的是**一串相同运算的指令**时，流水的效能才得以发挥，才能使各个功能段并行地对多条指令的数据进行流水处理

###### 动态流水线

在同一段时间内，多功能流水线中的各段可以按照不同的方式连接，同时执行多种功能

优点：能提高流水线的效率

缺点：会使流水线的控制变得复杂

![image-20231219104812470](imgs/155.png)

区别：如果从软硬功能分配的观点上来看，静态流水线其实是把功能负担较多地加到软件上，以简化硬件，动态流水线则是把功能负担较多地加在硬件上，以提高流水的效能。

##### 其他方法

###### 数据表示

* 标量处理机：不具有向量指令和向量数据表示，仅对标量进行流水处理的处理机。
* 向量处理机：具有向量指令和向量数据表示的处理机。

###### 是否有反馈回路

* 线性流水线：流水线中的各段串行连接，没有反馈回路。
* 非线性流水线：流水线中的各段除有串行连接外，还有反馈回路



非线性流水线必须用流水线连接图与流水线预约表等共同表示

###### 流动是否可以乱序

* 顺序流动流水线，流水线输出端任务流出的顺序与输入端任务流入的顺序相同。
* 异步流动流水线（乱序流水线/无序流水线/错序流水线），流水线输出端任务流出的顺序与输入端任务流入的顺序不同。 

![image-20231219105400666](imgs/156.png)



#### 线性流水线的性能分析

衡量流水线性能的主要指标有：吞吐率、加速比和效率

##### 吞吐率

求流水线吞吐率的最基本公式
$$
T_P=n/T_k
$$
n为任务数, Tk为完成n个任务所用时间

最大吞吐率TPmax是指流水线在连续流动达到稳定状态后所得到的吞吐率

![image-20231219105921009](imgs/157.png)

若各段执行时间相等，则输入连续任务情况下完成n个连续任务需要的总时间为
$$
T_k=(k+n-1)D_t
$$
k为流水线的段数，Dt为时钟周期
$$
TP=\frac n{(k+n-1)\Delta t}
$$

$$
TP\max=\underset{n\to\infty}{\operatorname*{Lim}}\frac n{(k+n-1)\Delta t}=\frac1{\Delta t}
$$

各段执行时间不相等、输入连续任务情况下
$$
TP=\frac n{\sum_{i=1}^kt_i+(n-1)\max(\Delta t_1,\Delta t_2,\cdot\cdot\cdot,\Delta t_k)}
$$

$$
TP_{\max}=\frac1{\max(\Delta t_1,\Delta t_2,\cdots,\Delta t_k)}
$$

流水线各段执行时间不相等的解决办法

![image-20231219110205100](imgs/158.png)

##### 加速比

$$
S=\text{顺序执行时间}T_0/\text{流水线执行时间}T_k
$$

各段执行时间相等，输入连续任务情况下加速比为
$$
S=\frac{k\cdot n\cdot\Delta t}{(k+n-1)\Delta t}=\frac{k\cdot n}{k+n-1}
$$
最大加速比为
$$
S_{\textrm{m a x}}= \lim_{n \to \infin} \frac{k\cdot n}{k+n-1}=k
$$
各段执行时间不等，输入连续任务情况下实际加速比为：
$$
S=\frac{n\cdot\sum\limits_{i=1}^{k}\Delta ti}{\sum\limits_{i=1}^{k}\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_2,\cdots,\Delta t_k)}
$$

##### 效率E

效率是指流水线的设备利用率

由于流水线有通过时间和排空时间，所以流水线的

各段并不是一直满负荷地工作。故：E ＜1

![image-20231219110844560](imgs/159.png)

若各段时间相等，则各段的效率$e_i$相等
$$
e_1=e_2=\cdots=e_k=n\Delta t_0/T_\text{流水}
$$

$$
E=\frac{n\Delta t_0}{T_\text{流水}} = \frac n { k + n - 1 }=\frac1{1+\frac{k-1}n}
$$

$n>>m,E \approx 1$

从时－空图上看，效率实际上就是 n 个任务所占的时空区与 k 个段总的时空区之比，即：
$$
E=\frac{n\text{个任务占用的时空区}}{ k\text{个流水段的总的时空区}} = \frac { T _ 0 }{ k \cdot T _ k}
$$
提高流水线效率所采取的措施对于提高吞吐率也有好处。

各流水段执行时间相等，输入n个连续任务流水线的效率为：
$$
E=\frac{k\cdot n\cdot\Delta t}{k\cdot(k+n-1)\cdot\Delta t}=\frac n{k+n-1}
$$
流水线的最高效率为
$$
E_{\max}\quad=\lim_{n\to\infty}\quad\frac{n}{k+n-1}=1
$$
各流水段执行时间不等，输入n个连续任务流水线的效率为
$$
E=\frac{n\cdot\sum_{i=1}^k\Delta t_i}{k\cdot[\sum_{i=1}^k\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_2,\cdots,\Delta t_k)]}
$$
流水线各段的设备量或各段的价格不相等时：
流水线的效率为
$$
E=\frac{n\cdot\sum_{i=1}^ka_i\cdot\Delta t_i}{\sum_{I=1}^{i=k}a_i\cdot[\sum_{i=1}^ka_i\cdot\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_2,,\Delta t_n)]}
$$
$\sum_{i=1}^k a_i=k$

##### 流水线的吞吐率、加速比与效率的关系

$$
\begin{aligned}TP&=\frac n{(k+n-1)\Delta t}\\S&=\frac{k\cdot n}{k+n-1}\\E&=\frac n{k+n-1}\end{aligned}
$$

$$
E=TP·\Delta t , S=k·E
$$

##### 性能分析举例

Z = [(A+B) + (C+D)] + [(E+F) + (G+H)]

![image-20231219141925167](imgs/160.png)

确定适合于流水处理的计算过程

画时－空图

计算性能



### 调度

[计算机体系结构——动态流水线&动态调度 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/586202303)

指令调度技术的一个前提是不改变程序正确性，通过改变指令的执行次序来避免由于指令相关引起的流水线阻塞

#### 静态指令调度

静态调度(static scheduling)是由优化的编译程序来完成，其基本思想是重排指令序列，拉开具有数据相关的有关指令间的距离。由于是用编译程序判测潜在的数据相关，并在程序运行之前完成调度，故称为静态调度

![image-20231219142638867](imgs/161.png)

* Basic block scheduling基础块调度
* Loop unrolling循环展开
* Software pipelining (modulo scheduling)软件流水
* Trace scheduling轨迹调度
* Predication预测

#### 动态指令调度

Expose more parallelism by ignoring artificial serial constraints of “sequential” program

Also called out-of-order issue (OOO-issue): instructions need not execute in original program order

寄存器重命名

精准中断

##### 冒险

data, structural, control

* Data: RAW (true data dependence), WAR ( anti-dependence), WAW (output dependence)
* Structural: Are the required resources available? 
* Control: Is this instruction supposed to execute or not? 

##### 实现-两种早期方法

Control flow 

Data flow – Tomasulo

* Simple idea – when opcode and operands are ready, and the appropriate set of resources are ready, launch the “execution packet”
* Interesting wrinkle – does not used named registers for intermediate storage
* Implicit introduction of Register Renaming

##### 动态调度的优势

* 处理实例当在编译期相关性未知
* 简化编译器
* 允许为一个流水线编译的代码在另一个流水线上高效运行
* 硬件推测，一种基于动态调度的具有显著性能优势的技术

##### 硬件策略：指令并行

* Key idea: Allow instructions behind stall to proceed

  DIVD F0,F2,F4
  ADDD F10,F0,F8
  SUBD F12,F8,F14

* Enables out-of-order execution and allows out-of-order completion

* Will distinguish when an instruction begins execution and when it completes execution; between 2 times, the instruction is in execution

* In a dynamically scheduled pipeline, all instructions pass through issue stage in order (in-order issue)

##### 流水线修改

基础的必须的流水线变化

* Stalled dependent instructions cannot block later independent instructions停滞的依赖指令无法阻塞以后的独立指令
* Split ID (decode stage) into two new stages将 ID（解码阶段）拆分为两个新阶段
  * DISPATCH (ID): instruction dispatchDISPATCH （ID）：指令调度
  * ISSUE (IS): instruction schedule / issue ISSUE （IS）：指令规划/问题
* The ISSUE stage buffers instructions waiting (stalled) for dataISSUE阶段缓冲等待（停止）数据的指令
* This allows later instructions to make progress (FETCH and DISPATCH are not stalled)这允许稍后的指令取得进展（FETCH 和 DISPATCH 不会停止）



无序流水线

##### scoreboard

* 仅当两个操作数在寄存器文件中都可用时，指令的操作数才是只读的
  * 记分牌不利用转发
  * 指令在完成执行后立即写入寄存器文件（假设没有 WAR 危害），并且不要等待写入插槽
  * 一个额外的延迟周期，因为写入结果和读取操作数阶段不能重叠
* 总线结构
  * 注册文件的总线数量有限代表结构性危险



三个数据结构

* 指令状态Which stage is the instruction in
* 功能单元状态
  * Busy	- FU is busy executing another instruction
  * Op	- What instruction is the FU busy with
  * Fi		- Destination register
  * Fj, Fk	- Source registers
  * Qj, Qk	- Functional units producing source registers
  * Rj, Rk	- Flags indicating source registers are ready
* 寄存器结果状态
  * Which FU is going to write each register



##### 分布式动态调度-Tomasulo

###### Tomasulo vs scoreboard

* 控制和缓冲区与功能单元（FU）一起分布，而不是集中在记分牌中;（旁路）
  * FU 缓冲区称为预留站;有挂起的操作数

* 指令中的寄存器由值或指向预订站（RS）的指针代替;称为寄存器重命名
  * 避免 WAR、WAW 危害
  * 预留站多于寄存器，因此可以进行编译器无法做到的优化

* 结果通过公共数据总线从 RS 传输到 FU，而不是通过寄存器，将结果广播到所有 Fu

* 加载和存储也被视为具有预订站的 FU
* 整数指令可以经过分支，允许 FP 操作超出 FP 队列中的基本块

###### tomasulo算法的关键方面

1. 在调度阶段读取寄存器操作数
   * 如果操作数可用，则数据将与“预订站”中的指令一起缓冲
   * CDC：仅缓冲指令，当所有操作数都准备好时，从寄存器文件中读取所有操作数（在问题阶段读取操作数）
   * CDC – 晚读 / Tomasulo – 早读：早读有助于 WAR 状况
2. 不可用的寄存器在调度阶段重命名
   * 等待指令将寄存器说明符替换为指示生产者指令的“标记”
   * 寄存器说明符在发货时仅使用一次！
   * 重命名消除了 WAR/WAW 危害
3. 连续写入寄存器
   * 实际上只有最后一个用于更新寄存器：帮助 WAW 条件
   * CDC：在WAW危害消失之前停止调度

###### DLX版本

提取后的四个阶段

* 调度
  * 检查结构危险
    * 如果没有免费预订站，则在调度阶段停滞不前
  * 读取寄存器文件
    * 读取数据操作数（如果可用）
    * 如果数据操作数不可用，则读取“标签”：标签是生产者指令的预留站号
  * 将指令和数据或标签路由到预订站，在那里等待，直到所有操作数都可用
* 发射
  * 等到操作数在 CDB 上可用（将 CDB 标记与操作数标记匹配）
  * 从 CDB 获取操作数并颁发给 FU（如果可用）
* 执行
* 写入结果
  * 通过CDB将结果+标签广播到所有预订站，存储缓冲区和注册文件
  * 仅当 CDB 标记与寄存器文件中的标记匹配时，才写入寄存器文件



![image-20231221232426047](imgs/162.png)

###### 数据结构

* 寄存器状态Register file stores either a tag or a value
* 指令状态This is for illustration only, not a real data structure

###### 保留站内容

* Op:	Operation to perform in the unit (e.g., + or –)
* Vj, Vk: Value of Source operands
  * Store buffers has V field, result to be stored
* Qj, Qk: Reservation stations producing source registers (value to be written)
  * Note: Qj,Qk=0 => ready
  * Store buffers only have Qi for RS producing result
* Busy: Indicates reservation station or FU is busy
* Register result status—Indicates which functional unit will write each register, if one exists. Blank when no pending instructions that will write that register.

###### tomasulo算法的三个阶段

1. 发射issue

   get instruction from FP Op Queue

   * If reservation station free (no structural hazard), control issues instr & 
   * sends operands (renames registers).

2. 执行execute

   operate on operands (EX）

   * When both operands ready then execute; 
   * if not ready, watch Common Data Bus for result

3. 写结果

   finish execution (WB)

   * Write on Common Data Bus to all awaiting units; 
   * mark reservation station available



* Normal data bus: data + destination (“go to” bus)
* Common data bus: data + source  (“come from” bus)
  * 64 bits of data + 4 bits of Functional Unit  source address
  * Write if matches expected Functional Unit (produces result)
  * Does the broadcast



### 超流水线处理机

一个周期内能够分时发射多条指令的处理机称为 超流水线处理机。    

指令流水线有8个或更多功能段的流水线处理机称为超流水线处理机。

提高处理机性能的不同方法：    

1. 超标量处理机是通过增加硬件资源为代价来换取处理机性能的。
2. 超流水线处理机则通过各硬件部件充分重叠工作来提高处理机性能。

两种不同并行性：    

1. **超标量处理机**采用的是空间并行性    
2. **超流水线处理机**采用的是时间并行性

#### 性能分析

指令级并行度为(1,n)的超流水线处理机，执行N条指令所的时间为
$$
T\left(1,n\right)=(k+\frac{N-1}n)\Delta t
$$
超流水线处理机相对于单流水线普通标量处理机的加速比为：
$$
S\left(1,n\right)=\frac{T\left(1,1\right)}{T\left(1,n\right)}=\frac{\left(k+N-1\right)\Delta t}{(k+\frac{N-1}n)\Delta t}
$$

$$
S(1,n)=\frac{n(k+N-1)}{nk+N-1}
$$

最大加速比为$\mathbf{S(1,n)}_{\mathbf{MAX}}=n$

#### 超标量超流水线处理机

把超标量与超流水线技术结合在一起，就成为超标量超流水线处理机

##### 指令执行时序

超标量超流水线处理机在一个时钟周期内分时发射指令n次，每次同时发射指令m条，每个时钟周期总共发射指令m × n条。

![image-20231224174902809](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20231224174902809.png)

##### 典型处理机结构

* DEC公司的Alpha处理机采用超标量超流水线结构。主要由四个功能部件和两个Cache组成：整数部件EBOX、浮点部件FBOX、地址部件ABOX和中央控制部件IBOX。
* 中央控制部件IBOX可以同时从指令Cache中读入两条指令，同时对读入的两条指令进行译码，并且对这两条指令作资源冲突检测，进行数据相关性和控制相关性分析。如果资源和相关性允许，IBOX就把两条指令同时发射给EBOX、ABOX和FBOX三个指令执行部件中的两个。
* 指令流水线采用顺序发射乱序完成的控制方式。在指令Cache中有一个转移历史表，实现条件转移的动态预测。在EBOX内还有多条专用数据通路，可以把运算结果直接送到执行部件。

##### 超标量流水线处理机性能

指令级并行度为(m,n)的超标量超流水线处理机，连续执行N条指令所需要的时间为
$$
T(m,n)=(k+\frac{N-m}{m\cdot n})\Delta t
$$
超标量超流水线处理机相对于单流水线标量处理机的加速比为
$$
\begin{aligned}
&\begin{aligned}S(m,n)=\frac{S(1,1)}{S(m,n)}&=\frac{(k+N-1)\Delta t}{(k+\frac{N-m}{mn})\Delta t}\end{aligned} \\
&\begin{aligned}S(m,n)=\frac{m\cdot n\cdot(k+N-1)}{m\cdot n\cdot k+N-m}\end{aligned}
\end{aligned}
$$
在理想情况下，超标量超流水线处理机加速比的最大值为
$$
S(m,n)_\text{MAX}{ = m n}
$$


三种指令级并行处理机性能比较

**超标量处理机**、**超流水线处理机**和**超标量超流水线处理机**相对于单流水线普通标量处理机的性能曲线。

![image-20231224175404083](imgs/163.png)

从三种指令级并行处理机的性能曲线中，可以得出如下结论:

1. 三种处理机的性能关系      

   超标量处理机的相对性能最高，其次是超标量超流水线处理机，超流水线处理机的相对性能最低，主要原因如下：      

   1. 超标量处理机在每个时钟周期的一开始就同时发射多条指令，而超流水线处理机则要把一个时钟周期平均分成多个流水线周期，每个流水线周期发射一条指令；因此，超流水线处理机的启动延迟比超标量处理机大。
   2. 条件转移造成的损失，超流水线处理机要比超标量处理机大。
   3. 在指令执行过程中的每一个功能段，超标量处理机都重复设置有多个相同的指令执行部件，而超流水线处理机只是把同一个指令执行部件分解为多个流水级；因此，超标量处理机指令执行部件的冲突要比超流水线处理机小

2. 实际指令级并行度与理论指令级并行度的关系

   当横坐标给出的理论指令级并行度比较低时，处理机的实际指令级并行度的提高比较快。    

   当理论指令级并行度进一步增加时，处理机实际指令级并行度提高的速度越来越慢。    

   在实际设计超标量、超流水线、超标量超流水线处理机的指令级并行度时要适当，否则，有可能造成花费了大量的硬件，但实际上处理机所能达到的指令级并行度并不高。    

   目前，一般认为，m 和 n 都不要超过4。

3. 最大指令级并行度

   一个特定程序由于受到本身的数据相关和控制相关的限制，它的指令级并行度的最大值是有限的，是有个确定的值。这个最大值主要由程序自身的语义来决定，与这个程序运行在那一种处理机上无关。对于某一个特定的程序，图中的三条曲线最终都要收拢到同一个点上。当然，对于各个不同程序，这个收拢点的位置也是不同的。


## 余爹押题

十大题

填空题20分

九大题80分

### 第七章

开关

### 第六章

向量优化

向量处理方式，向量处理

### 第五章

相关性，处理相关性，针对计算流水性能分析

静态动态

先后算，

RAW去除

### 第四章

IO输入输出：中断优先级

IOP 通道 最大流量 工作周期

通道与设备是否能连接

### 第三章

存储系统

存储系统层次、目标 交叉

地址变换提速

cache性能优化

替换算法

堆栈替换算法

### 第二章

指令系统

指令构成

寻址方式 间接寻址、变址寻址-》扩充寻址空间；立即寻址

频度分析

指令格式优化 操作码 操作数 优化方法 **下一指令标记**

两种指令系统cisc risc 使用的技术

### 第一章

填空概念

CPI计算

阿姆达尔定理

设计原理

局部性原理



















